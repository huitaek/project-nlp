{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 3.8 만들기\n",
    "# conda create -n conda38 python=3.8 anaconda\n",
    "# conda install python = 3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dkq50\\anaconda3\\envs\\conda38\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-win_amd64.whl (2.8 MB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.0-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dkq50\\anaconda3\\envs\\conda38\\lib\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dkq50\\anaconda3\\envs\\conda38\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dkq50\\anaconda3\\envs\\conda38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dkq50\\anaconda3\\envs\\conda38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=552d274a18340bb7e18504645b40247646f64e6343a919372a9c211c232d7934\n",
      "  Stored in directory: c:\\users\\dkq50\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, zipp, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 charset-normalizer-2.0.12 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.6.0 idna-3.3 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 typing-extensions-4.1.1 urllib3-1.26.9 werkzeug-2.0.3 wrapt-1.14.0 zipp-3.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dkq50\\OneDrive\\바탕 화면\\자연어처리\\프로젝트\\project-nlp-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('./data/ratings.txt',header = 0, delimiter = '\\t', quoting=3)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 : 200000\n"
     ]
    }
   ],
   "source": [
    "print('전체 리뷰 개수 :',len(ratings)) # 전체 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "null값을 확인 및 중복값을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 194543, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['id'].nunique(), ratings['document'].nunique(), ratings['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    8\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings.dropna(axis=0)\n",
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop_duplicates(subset = [\"document\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복값 제거 후 : 194543\n"
     ]
    }
   ],
   "source": [
    "print('중복값 제거 후 :',len(ratings)) # 전체 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(ratings.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 영화 평 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>739929959</td>\n",
       "      <td>누가 도깨비에요?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>597672743</td>\n",
       "      <td>진심 망작..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597585065</td>\n",
       "      <td>셍각보다 재미났어요 \\n코믹케릭도 괜찮고 설정도 재미났어요 ㅎ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>597562997</td>\n",
       "      <td>3탄 가즈아~~~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>597560513</td>\n",
       "      <td>일진시리즈중 최고네요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                            document  label\n",
       "0  739929959                           누가 도깨비에요?      0\n",
       "1  597672743                             진심 망작..      0\n",
       "2  597585065  셍각보다 재미났어요 \\n코믹케릭도 괜찮고 설정도 재미났어요 ㅎ      1\n",
       "3  597562997                           3탄 가즈아~~~      1\n",
       "4  597560513                         일진시리즈중 최고네요      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daum = pd.read_csv('./data/comment_suc.csv', encoding = 'cp949')\n",
    "daum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 : 2992\n"
     ]
    }
   ],
   "source": [
    "print('전체 리뷰 개수 :',len(daum)) # 전체 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2992, 2869, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daum['id'].nunique(), daum['document'].nunique(), daum['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복제거 후 : 2869\n"
     ]
    }
   ],
   "source": [
    "daum.drop_duplicates(subset=['document'], inplace=True) # reviews 열에서 중복인 내용이 있다면 중복 제거\n",
    "print('중복제거 후 :',len(daum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(daum.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수 : 197412\n"
     ]
    }
   ],
   "source": [
    "Data = pd.concat([ratings, daum])\n",
    "print('전체 데이터 수 :', len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰의 개수 : 177670\n",
      "테스트용 리뷰의 개수 : 19742\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(Data, test_size=0.1, random_state=220320)\n",
    "print('훈련용 리뷰의 개수 :', len(train))\n",
    "print('테스트용 리뷰의 개수 :', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 내보내기\n",
    "train.to_csv('./data/train_data.csv', encoding='cp949') \n",
    "test.to_csv('./data/test_data.csv', encoding='cp949') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 편향되지 않기 위해서는 label이 균일하게 분포되어있는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  count\n",
      "0      0  87953\n",
      "1      1  88745\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['label'].value_counts().plot(kind = 'bar')\n",
    "print(train.groupby('label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글을 제외한 나머지는 빈칸으로 바꿔주고 빈칸을 null로 바꾼다음 null값을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkq50\\AppData\\Local\\Temp\\ipykernel_18768\\2353780523.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "C:\\Users\\dkq50\\AppData\\Local\\Temp\\ipykernel_18768\\2353780523.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['document'] = test['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "C:\\Users\\dkq50\\AppData\\Local\\Temp\\ipykernel_18768\\2353780523.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['document'] = train['document'].str.replace('^ +', \"\")\n",
      "C:\\Users\\dkq50\\AppData\\Local\\Temp\\ipykernel_18768\\2353780523.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['document'] = test['document'].str.replace('^ +', \"\")\n"
     ]
    }
   ],
   "source": [
    "train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test['document'] = test['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "\n",
    "train['document'] = train['document'].str.replace('^ +', \"\")\n",
    "test['document'] = test['document'].str.replace('^ +', \"\")\n",
    "train['document'].replace('', np.nan, inplace = True)\n",
    "test['document'].replace('', np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64 \n",
      " id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = train.dropna(axis=0)\n",
    "test = test.dropna(axis=0)\n",
    "print(train.isnull().sum(), '\\n', test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('./data/stopwords2.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(a['stopwords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장을 단어단위로 쪼개어 리스트에 넣어주는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = [] \n",
    "t_test = []\n",
    "for sentence in train['document']:\n",
    "    temp_X = okt.morphs(sentence, stem = True) \n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    t_train.append(temp_X)\n",
    "    \n",
    "for sentence in test['document']:\n",
    "    temp_X = okt.morphs(sentence, stem = True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    t_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쪼개진 단어들에 숫자를 붙여주었다. 딥러닝을 위한 단계!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(t_train)\n",
    "tokenizer.fit_on_texts(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "## Save pickle\n",
    "with open(\"./data/movie.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(tokenizer, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 50201\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 27715\n",
      "단어 집합에서 희귀 단어의 비율: 55.20806358439076\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.5606006271091373\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt) * 100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등장 빈도가 threshold 값인 3회 미만. 즉, 2회 이하인 단어들은 단어 집합에서 무려 절반 이상을 차지합니다. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 1.56%밖에 되지 않습니다. 아무래도 등장 빈도가 2회 이하인 단어들은 자연어 처리에서 별로 중요하지 않을 듯 합니다. 그래서 이 단어들은 정수 인코딩 과정에서 배제시키겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등장 빈도수가 2이하인 단어들의 수를 제외한 단어의 개수를 단어 집합의 최대 크기로 제한하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 22487\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "# 0번 패딩 토큰을 고려하여 + 1\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = tokenizer.texts_to_sequences(t_train)\n",
    "X_test1 = tokenizer.texts_to_sequences(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61, 162, 34, 162, 156, 146], [217, 105, 702], [364, 1356, 92, 361, 5111, 2, 1641, 6839, 2299]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train1[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플 내의 단어들은 각 단어에 대한 정수로 변환된 것을 확인할 수 있습니다. 단어의 개수는 22,487개로 제한되었으므로 0번 단어 ~ 22,487번 단어까지만 사용 중입니다. 0번 단어는 패딩을 위한 토큰임을 상기합시다. train_data에서 y_train과 y_test를 별도로 저장해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train['label'])\n",
    "y_test = np.array(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최대 길이 : 127\n",
      "문장의 평균 길이 : 10.916201654800847\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('문장의 최대 길이 :',max(len(l) for l in X_train1)) # 단어의 수\n",
    "print('문장의 평균 길이 :',sum(map(len, X_train1))/len(X_train1))\n",
    "plt.hist([len(s) for s in X_train1], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 45 이하인 샘플의 비율: 99.52914011477209\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))\n",
    " \n",
    "# 이 값이 얼마나 많은 리뷰 길이를 커버하는지 확인.\n",
    "max_len = 45\n",
    "below_threshold_len(max_len, X_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "길이를 길게 잡을 경우 학습에 시간이 오래걸리기 때문에 가장 데이터손실이 적으면서도 학습시간을 줄일 수 있도록 전체의 99.43%를 포함하도록 문장길이를 45로 설정하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pad_sequences(X_train1, maxlen = max_len)\n",
    "X_test2 = pad_sequences(X_test1, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 100)         2248700   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 128)         117248    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,465,149\n",
      "Trainable params: 2,465,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2210 - acc: 0.6466\n",
      "Epoch 1: val_acc improved from -inf to 0.77881, saving model to bilstm.h5\n",
      "24/24 [==============================] - 95s 4s/step - loss: 0.2210 - acc: 0.6466 - val_loss: 0.1591 - val_acc: 0.7788\n",
      "Epoch 2/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1342 - acc: 0.8167\n",
      "Epoch 2: val_acc improved from 0.77881 to 0.82756, saving model to bilstm.h5\n",
      "24/24 [==============================] - 89s 4s/step - loss: 0.1342 - acc: 0.8167 - val_loss: 0.1244 - val_acc: 0.8276\n",
      "Epoch 3/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1060 - acc: 0.8582\n",
      "Epoch 3: val_acc improved from 0.82756 to 0.83724, saving model to bilstm.h5\n",
      "24/24 [==============================] - 88s 4s/step - loss: 0.1060 - acc: 0.8582 - val_loss: 0.1167 - val_acc: 0.8372\n",
      "Epoch 4/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.8738\n",
      "Epoch 4: val_acc improved from 0.83724 to 0.83984, saving model to bilstm.h5\n",
      "24/24 [==============================] - 89s 4s/step - loss: 0.0950 - acc: 0.8738 - val_loss: 0.1154 - val_acc: 0.8398\n",
      "Epoch 5/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.8843\n",
      "Epoch 5: val_acc improved from 0.83984 to 0.84015, saving model to bilstm.h5\n",
      "24/24 [==============================] - 89s 4s/step - loss: 0.0886 - acc: 0.8843 - val_loss: 0.1175 - val_acc: 0.8402\n",
      "Epoch 6/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0838 - acc: 0.8916\n",
      "Epoch 6: val_acc did not improve from 0.84015\n",
      "24/24 [==============================] - 89s 4s/step - loss: 0.0838 - acc: 0.8916 - val_loss: 0.1199 - val_acc: 0.8385\n",
      "Epoch 7/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0797 - acc: 0.8984\n",
      "Epoch 7: val_acc did not improve from 0.84015\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0797 - acc: 0.8984 - val_loss: 0.1284 - val_acc: 0.8301\n",
      "Epoch 8/15\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0774 - acc: 0.9023\n",
      "Epoch 8: val_acc did not improve from 0.84015\n",
      "24/24 [==============================] - 91s 4s/step - loss: 0.0774 - acc: 0.9023 - val_loss: 0.1234 - val_acc: 0.8372\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.5)) # 구글링의 결과 0.2 ~ 0.5이 적합하다고 나옴\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.5)) # 0.5 이하로는 과대적합의 경향이 많이 나타남\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('bilstm.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "history = model.fit(X_train2, y_train, epochs=15, callbacks=[es, mc], batch_size=6000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss : 훈련 손실값\n",
    "- acc : 훈련 정확도\n",
    "- val_loss : 검증 손실값\n",
    "- val_acc : 검증 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615/615 [==============================] - 10s 15ms/step - loss: 0.1164 - acc: 0.8408\n",
      "\n",
      " 테스트 정확도: 0.8408\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('bilstm.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test2, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "from konlpy.tag import Okt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "okt = Okt()\n",
    "loaded_model = load_model('bilstm.h5')\n",
    "max_len = 42\n",
    "\n",
    "global corpus\n",
    "global avg_emo\n",
    "global score\n",
    "\n",
    "corpus = []\n",
    "avg_emo = 0\n",
    "\n",
    "\n",
    "heal = ['여수 밤바다', '파주 평화누리공원', '순천 갈대밭', '제주도 영실코스', \n",
    "         '진주 진양호', '장흥유원지', '대구 앞산정만대', '춘천 해피초원농장' ,' 속초 해수욕장', \n",
    "         '경주 불국사', '포항 호미곶', '남해 두모마을', '대관령 하늘목장', '군산 철길마을', \n",
    "         '국립 광릉수목원', '금선사 템플스테이', '보성 제암산자연휴양림','군산 선유도']\n",
    " \n",
    "extreme= ['통영 어드벤처 타워', '제주도  스쿠버다이빙', '단양 패러글라이딩', \n",
    "          '강원 내린천 래프팅', '충주 스카이다이빙', '하남 스포츠몬스터', '서울 한강 워터 제트팩', \n",
    "          '일산 인공 서핑', '영월 동강래프팅', '여수 스카이플라이', '문경 패러글라이딩', \n",
    "          '경남 하동 하동알프스레포츠', '인천 스카이 짚라인', '강화 루지']\n",
    " \n",
    "movie=['루카','콰이어트 플레이스','크루엘라','컨저링 3:악마가 시켰다','여고괴담 여섯번째 이야기','분노의 질주: 더 얼티메이트','캐시트럭',\n",
    "'클라이밍',\n",
    "'그 여름, 가장 차가웠던',\n",
    "'폭력의 그림자',\n",
    "'청춘 선거',\n",
    "'그레타 툰베리',\n",
    "'낫아웃',\n",
    "'마세티 킬즈',\n",
    "'프로페서 앤 매드맨',\n",
    "'화이트 온 화이트',\n",
    "'아야와 마녀',\n",
    "'까치발',\n",
    "'플래시백',\n",
    "'애플',\n",
    "'혼자 사는 사람들',\n",
    "'강호아녀',\n",
    "'파이프라인',\n",
    "'분노의 질주']\n",
    " \n",
    "#음악 (네이버 바이브 참고 1위~20위)\n",
    " \n",
    "k_balad=['Timeless-SG워너비',\n",
    "'추적이는 여름 비가 되어-장범준',\n",
    "'밤하늘의 별을 (2020)-경서',\n",
    "'어떻게 이별까지 사랑하겠어, 널 사랑하는 거지-AKMU (악동뮤지션)',\n",
    "'내 입술 따뜻한 커피처럼-청하 Colde(콜드)',\n",
    "'서울의 잠 못 이루는 밤 (Feat. 이수현)-10CM',\n",
    "'잠이 오질 않네요-장범준',\n",
    "'I Love U-성시경',\n",
    "'내사람 (Partner For Life)-SG워너비',\n",
    "'취기를 빌려-산들',\n",
    "'안녕 (Hello)-조이',\n",
    "'밤편지-아이유(IU)',\n",
    "'Anti-Romantic-투모로우바이투게더',\n",
    "'너의 모든 순간-성시경',\n",
    "'좋을텐데 (If Only) (Feat. 폴킴)-조이',\n",
    "'봄 안녕 봄-아이유(IU)',\n",
    "'Love poem -아이유(IU)',\n",
    "'아이와 나의 바다-아이유(IU)',\n",
    "'벌써 일년-반하나& MJ(써니사이드)',\n",
    "'이렇게 좋아해 본 적이 없어요 -CHEEZE (치즈)'\n",
    "]\n",
    " \n",
    "k_dance=[\n",
    "'Butter-방탄소년단',\n",
    "'Next Level-aespa',\n",
    "'Dun Dun Dance-오마이걸(OH MY GIRL)',\n",
    "'치맛바람 (Chi Mat Ba Ram)-브레이브걸스(Brave Girls)',\n",
    "'Alcohol-Free-TWICE(트와이스)',\n",
    "\"롤린 (Rollin')-브레이브걸스(Brave Girls)\",\n",
    "'라일락-아이유(IU)',\n",
    "'ASAP-STAYC(스테이씨)',\n",
    "'Dynamite-방탄소년단',\n",
    "'상상더하기-MSG워너비',\n",
    "'Celebrity-아이유(IU)',\n",
    "'상상더하기-라붐(LABOUM)',\n",
    "'Ready to love-세븐틴',\n",
    "'Dolphin-오마이걸(OH MY GIRL)',\n",
    "'Lovesick Girls-BLACKPINK',\n",
    "'Pool Party (Feat. 이찬 of DKB)-브레이브걸스(Brave Girls)',\n",
    "\"Heaven's Cloud-세븐틴\",\n",
    "'체념-정상동기(김정수, 정기석, 이동휘, 이상이)',\n",
    "'어푸 (Ah puh)-아이유(IU)',\n",
    "]\n",
    " \n",
    "k_hip=[\n",
    "'마.피.아. In the morning-ITZY(있지)',\n",
    "'봄날-방탄소년단',\n",
    "'Life Goes On-방탄소년단',\n",
    "'맛 (Hot Sauce)-NCT DREAM',\n",
    "'밸런스 게임-투모로우바이투게더',\n",
    "'GAM3 BO1-세븐틴',\n",
    "'비도 오고 그래서 (Feat. 신용재)-헤이즈 (Heize)',\n",
    "'METEOR-창모(CHANGMO)',\n",
    "'DNA-방탄소년단',\n",
    "'IDOL-방탄소년단',\n",
    "'FAKE LOVE-방탄소년단',\n",
    "'피 땀 눈물-방탄소년단',\n",
    "'사이렌-호미들',\n",
    "'멜로디-ASH ISLAND',\n",
    "'I NEED U-방탄소년단',\n",
    "'아무노래-지코 (ZICO)',\n",
    "'어떻게 지내 (Prod. By VAN.C)-오반(OVAN)',\n",
    "'Rainy day (Feat. ASH ISLAND, Skinny Brown)-PATEKO(파테코)',\n",
    "'뚜두뚜두 (DDU-DU DDU-DU)-BLACKPINK']\n",
    " \n",
    " \n",
    "trt=[\n",
    "'이제 나만 믿어요-임영웅',\n",
    "'별빛 같은 나의 사랑아-임영웅',\n",
    "'다시 사랑한다면 (김필 Ver.)-임영웅',\n",
    "'HERO-임영웅',\n",
    "'미워요-임영웅',\n",
    "'잊어야 한다는 마음으로-임영웅',\n",
    "'계단말고 엘리베이터-임영웅',\n",
    "'소나기-임영웅',\n",
    "'바보같지만-임영웅',\n",
    "'따라따라-임영웅',\n",
    "'당신-임영웅',\n",
    "'내 마음 별과 같이-임영웅',\n",
    "'고맙소-김호중',\n",
    "'만개 (Prod. 신지후)-김호중',\n",
    "'나보다 더 사랑해요-김호중',\n",
    "'애인이 되어줄게요 (Prod. 알고보니, 혼수상태)-김호중',\n",
    "'퇴근길-김호중',\n",
    "'할무니-김호중',\n",
    "'우산이 없어요-김호중',\n",
    "'천년의 사랑-김호중'\n",
    "]\n",
    " \n",
    " \n",
    "f_dance=[\n",
    "'You-Regard, Troye Sivan, Tate McRae',\n",
    "'Closer (Feat. Halsey)-The Chainsmokers',\n",
    "'Faded-Alan Walker',\n",
    "'One Kiss-Calvin Harris, Dua Lipa',\n",
    "'Heartbreak Anthem-Galantis, David Guetta, Little Mix',\n",
    "'Something Just Like This-The Chainsmokers, Coldplay',\n",
    "'This Is What You Came For (Feat. Rihanna)-Calvin Harris',\n",
    "'The Middle-Zedd, Grey, Maren Morris',\n",
    "'Symphony (Feat. Zara Larsson)-Clean Bandit',\n",
    "'Wake Me Up-Avicii',\n",
    "'Waste It On Me (Feat. BTS(방탄소년단))-Steve Aoki',\n",
    "'How To Love (Feat. Sofia Reyes)-Cash Cash',\n",
    "'Bad Boy (with Wiz Khalifa, bbno$, MAX)-Yung Bae, Wiz Khalifa, bbno$, MAX',\n",
    "'Titans (Feat. Sia & Labrinth) (Imanbek Remix)-Major Lazer',\n",
    "'Feels (Feat. Pharrell Williams, Katy Perry, Big Sean)-Calvin Harris',\n",
    "'Rise (Feat. Jack & Jack)-Jonas Blue',\n",
    "'Mama (Feat. William Singe)-Jonas Blue',\n",
    "'Just Got Paid (Feat. French Montana)-Sigala, Ella Eyre, Meghan Trainor',\n",
    "'Love Line-Shift K3y, Tinashe',\n",
    "'Lonely Together (Feat. Rita Ora)-Avicii'\n",
    "]\n",
    " \n",
    "newage=[\n",
    "'River Flows In You-이루마',\n",
    "'Letter From The Earth (지구에서 온 편지)-김광민',\n",
    "'익숙한 그 집 앞-유희열',\n",
    "'처음부터 지금까지 (Inst.)-박정원',\n",
    "'냉정과 열정 사이 OST (冷靜と情熱のあいだ)-Ryo Yoshimata',\n",
    "'''Tomorrow's Promise-Kevin Kern''',\n",
    "\"Mia & Sebastian's Theme-Justin Hurwitz\",\n",
    "'Recuerods de la Alhambra (알함브라 궁전의 추억)-Claude Ciari',\n",
    "'''Gabriel's Oboe-Ennio Morricone''',\n",
    "'Rain-Ryuichi Sakamoto',\n",
    "'Romance-Yuhki Kuramoto',\n",
    "'Second Romance-Yuhki Kuramoto',\n",
    "'Crystal Rainbow-데이드림(Daydream)',\n",
    "'My Road (Live)-Lee Oskar',\n",
    "'Last Carnival-Acoustic Cafe',\n",
    "'Return To The Heart-David Lanz',\n",
    "'Adagio-Secret Garden',\n",
    "'Loving You-Kenny G'\n",
    "]\n",
    "\n",
    "korean = [\"삼계탕\", \"삼겹살\", \"곱창\", \"찜닭\", \"오리고기\", \"소고기\", \n",
    "          \"국밥\", \"닭도리탕\", \"낙곱새\", \"라면\", \"비빔밥\", \"칼국수\", \n",
    "          \"수제비\", \"갈비\", \"제육볶음\"]\n",
    "\n",
    "western = [\"스테이크\", \"파스타\", \"필라프\", \"감바스\", \"리조또\", \"샐러드\", \n",
    "           \"피자\", \"빠에야\", \"플래터\", \"스튜\"]\n",
    "\n",
    "asian = [\"짜장면\", \"뿌팟퐁커리\", \"팟타이\", \"나시고랭\", \"쌀국수\", \"미고랭\",\n",
    "         \"카레\", \"마라탕\", \"마라샹궈\", \"훠궈\", \"돈까스\", \"월남쌈\", \"라멘\", \n",
    "         \"탄탄멘\", \"규동\", \"꿔바로우\", \"똠양꿍\", \"물냉면\"]\n",
    "\n",
    "spicy = [\"떡볶이\", \"김치찜\", \"김치찌개\", \"감자탕\", \"짬뽕\", \"닭발\", \"부대찌개\",\n",
    "         \"순두부찌개\", \"아구찜\", \"해물찜\", \"육개장\", \"낙지볶음\", \"쭈꾸미\", \n",
    "         \"돼지갈비찜\", \"소꼬리찜\", \"비빔냉면\"]\n",
    "\n",
    "dessert = [\"와플\", \"마카롱\", \"빙수\", \"크로크모슈\", \"케이크\", \"허니바게트볼\",\n",
    "           \"머쉬룸수프볼\", \"에그데니쉬\", \"케이크\", \"치아바타\", \"호두파운드케이크\",\n",
    "           \"쿠키\", \"허니브레드\", \"오믈렛\", \"베이글\"]\n",
    "\n",
    "snack = [\"닭강정\", \"양꼬치\", \"핫윙\", \"소떡소떡\", \"가라아게\", \"콘치즈\", \"감자튀김\", \n",
    "         \"치킨너겟\", \"치킨\", \"낫쵸\", \"소시지\", \"버터구이\", \"계란찜\", \"핫도그\", \n",
    "         \"해쉬브라운\"]\n",
    "\n",
    "coffee = [\"아메리카노\", \"콜드브루\", \"바닐라 라떼\", \"카페 라떼\", \"카라멜 마키아또\",\n",
    "          \"카페 모카\", \"바닐라 프라페\", \"카페모카 프라페\", \"연유 라떼\", \"화이트 모카\",\n",
    "          \"민트 모카\", \"헤이즐넛 라떼\", \"에스프레소\", \"오곡 프라페\", \"쿠앤크 프라페\"]\n",
    "\n",
    "beverage = [\"초코 라떼\", \"민트초코 라떼\", \"밀크티\", \"흑당 버블티\", \"레몬차\", \"자몽차\",\n",
    "            \"유자차\", \"모히토\", \"요거트 스무디\", \"블루베리 스무디\", \"딸기 스무디\", \"애플망고 스무디\",\n",
    "            \"레몬 에이드\", \"자몽 에이드\", \"생과일 주스\"]\n",
    "\n",
    "motivation = [\"자신을 믿어라. 자신의 능력을 신뢰하라. 겸손하지만 합리적인 자신감 없이는 성공할 수도 행복할 수도 없다. - 노먼 빈센트 필\",\n",
    "\"조금 더 많이 인내하자. 조금 더 많이 노력하자. 그러면 절망적 실패로 보였던 것이 빛나는 성공으로 변할 수 있다. - 알버트 휴버드\",\n",
    "\"당신이 인생의 주인공이기 때문이다. 그 사실을 잊지말라. 지금까지 당신이 만들어온 의식적 그리고 무의식적 선택으로 인해 지금의 당신이 있는것이다. - 바바라 홀\",\n",
    "\"먹는 칼로리보다 에너지 소모가 적으면 살이 찌듯이, 걱정만 하고 행동하지 않으면 걱정이 찐다.\",\n",
    "\"이미 끝나버린 일을 후회하기 보다는 하고 싶었던 일을 하지 못한 것을 후회하라 - 탈무드\",\n",
    "\"기회가 주어지면 최선을 다하는 것이 아니라 최선을 다하고 있으면 기회가 주어지는 것이다 - 신영준\",\n",
    "\"낭비한 시간에 대한 후회는 더 큰 시간 낭비이다 - 메이슨 쿨리\",\n",
    "\"성공은 매일 부단하게 반복된 작은 노력의 합산이다.\",\n",
    "\"현명한 사람은 앉아서 손해 본 것을 한탄만 하지 않고 즐겁게 그 손해를 회복할 방법을 찾는다. - 셰익스피어\",\n",
    "\"고통을 주지 않는것은 쾌락도 주지 않는다 - 몽테뉴\",\n",
    "\"시간은 간다\",\n",
    "\"살아가는 사람들 중 대부분은 자신에게 올 기회를 기다리나 기회라는 것은 기다리는 사람에게는 쉽게 오지 않는 법이다\",\n",
    "\"기회를 얻을 수 있게 기다리는 사람이 되기보다는 기회를 얻을 수 있는 실력을 먼저 쌓아야 한다. 자신이 하는 일에 열중하고 노력하다보면 자연스럽게 기회는 찾아온다.\",\n",
    "\"변화를 위해서 가장 중요한 것은 행동하는 첫걸음이다.\",\n",
    "\"무엇이든 하루아침에 만들어지는 것은 없다. 로마 또한 하루아침에 만들어지지 않았다. 이 말은 무언가를 만들기 위해서는 그것을 만들기 위해 노력하고 집중 해야 한다는 것이다.\",\n",
    "\"스스로를 믿고 자신이 가지고 있는 능력을 신뢰해야 한다. 하지만 거만하게 행동하지 말고 겸손해라. 성공을 위해서 자신감이 필요하지만 오만함은 필요하지 않다.\",\n",
    "             \"끝난 일은 언급할 필요가 없으며 지난 일은 허물을 물을 필요가 없다. - 공자\",\n",
    "\"어렵고 힘든 상황일수록 서두르지 말고 침착해라. 성급하게 하는 행동에는 실수가 포함되기 쉽다.\",\n",
    "\"나의 하루를 설명할 수 있는 사람이 곁에 있다는 건 생각보다 기분 좋은 일이야 그러니 너도 생각보다 좋은 사람이지 - 흔글\",\n",
    "\"잠 못 자고 있지, 얼른 자, 걱정하는 일 안 생겨 좋은 일은 아니더라도 아무 일 없을 거야 혼자 있는 새벽을 걱정으로 보내지는 마 - 흔글\",\n",
    "\"봄바람도 살랑살랑 불고 꽃도 예쁘게 피어있으니 얼마나 놀고 싶겠냐만은, 그래도 그 시간들을 이겨내면 너의 인생에 꽃이 필 테니 조금만 참고 바람을 이겨내기를 - 흔글\"]\n",
    "\n",
    "category = [heal,extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f8 = [extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f6 = [extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f3 = [heal,extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage, dessert]\n",
    "f1 = [heal,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage, dessert]\n",
    "f0 = [heal,movie,k_balad,k_dance,k_hip,f_dance,newage,korean,western,asian,spicy,spicy,dessert,snack,snack,coffee,beverage]\n",
    "\n",
    "def recomend_sys(new_sentence):\n",
    "    global score\n",
    "    global timecheck\n",
    "    global corpus\n",
    "    global score\n",
    "    global avg_emo\n",
    "\n",
    "    print(new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new)) # 예측\n",
    "    \n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))\n",
    "      \n",
    "    corpus.append(score)\n",
    "    if len(corpus) >= 5:\n",
    "        avg_emo = sum(corpus)/len(corpus)\n",
    "        if(avg_emo > 0.8):\n",
    "            pick = random.choice(f8)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘처럼 좋은 날엔 {0} 어떠신가요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "\n",
    "        elif(avg_emo > 0.6): \n",
    "            pick = random.choice(f6)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"좋은 일있으신가요? 오늘 {0} 어떠세요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.4) :\n",
    "            pick = random.choice(category)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘같은 날에는 {0} 어때요? 기분이 좋아질거에요!!\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.3) :\n",
    "            pick = random.choice(f3)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"꿀꿀한 오늘 {0} 추천해요.\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.18) :\n",
    "            pick = random.choice(f1)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘 {0} 어떠세요? 안좋은 기분을 환기시켜줄 거에요.\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        else:\n",
    "            pick = random.choice(f0)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘 안좋은 일이 있으셨나요. 오늘같은 날 {0} 어떠세요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "    else:\n",
    "        print('감정 분석까지 {0}개의 문장이 남았어요!'.format(5-len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 분석까지 4개의 문장이 남았어요!\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 분석까지 3개의 문장이 남았어요!\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 분석까지 2개의 문장이 남았어요!\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 분석까지 1개의 문장이 남았어요!\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기분 점수 : 42.53\n",
      "오늘같은 날에는 모히토 어때요? 기분이 좋아질거에요!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### okt 전처리 해놓은걸로 해보기!! (패딩까지 다 진행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dkq50\\OneDrive\\바탕 화면\\자연어처리\\프로젝트\\project-nlp-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/okt/X_train.csv')\n",
    "X_test = pd.read_csv('./data/okt/X_test.csv')\n",
    "y_train = pd.read_csv('./data/okt/y_train.csv')\n",
    "y_test = pd.read_csv('./data/okt/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최대 길이 : 45\n",
      "문장의 평균 길이 : 45.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf5ElEQVR4nO3dfZhWdb3v8fcnCNRKgSCPgja4pQe0dOuIdGX7WBRidsLOUYNdGzS2XKWW7dM2sTrZ9uFKTw8YPbijQNHckhc9yEkS2QpZO0EGMR40NxNoDGmQID4VCH7PH+s37eVwz3DPzFr3zcx8Xte1rlnru37rXt9fk/NlrfW7f0sRgZmZWZFeVe8EzMys93FxMTOzwrm4mJlZ4VxczMyscC4uZmZWuP71TuBAMXTo0GhoaKh3GmZmPcqqVav+FBHD2sZdXJKGhgaamprqnYaZWY8i6YlK8dJui0maK2mrpHVt4p+U9FtJ6yX931z8CknNkh6TdEYuPiHFmiXNyMVHSlqR4j+UNCDFB6bt5rS/oaw+mplZZWU+c7kZmJAPSHo3MBE4ISKOA76a4qOBScBx6ZjvSOonqR/wbeBMYDQwObUFuB6YGRHHAjuAaSk+DdiR4jNTOzMzq6HSiktE3A9sbxP+BHBdROxKbbam+ERgfkTsiohNQDMwJi3NEbExInYD84GJkgS8B1iQjp8HnJ37rHlpfQEwLrU3M7MaqfVosTcB70q3q34h6ZQUHw5szrVrSbH24q8HnomIPW3ir/istH9nar8PSdMlNUlq2rZtW7c7Z2ZmmVoXl/7AEGAscBlwRz2vKiJidkQ0RkTjsGH7DHYwM7MuqnVxaQF+HJkHgZeBocAW4KhcuxEp1l78aWCQpP5t4uSPSfsPS+3NzKxGal1cfgq8G0DSm4ABwJ+AhcCkNNJrJDAKeBBYCYxKI8MGkD30XxjZVM5LgXPS504F7kzrC9M2af994amfzcxqqrTvuUi6HTgdGCqpBbgSmAvMTcOTdwNT0x/+9ZLuAB4B9gAXR8Te9DmXAIuBfsDciFifTnE5MF/SNcBqYE6KzwFuldRMNqBgUll9NDOzyuR/1GcaGxvDX6I0M+scSasiorFt3N/QNzvANcy4q2L88evOqnEmZtXzxJVmZlY4FxczMyuci4uZmRXOxcXMzArn4mJmZoVzcTEzs8K5uJiZWeFcXMzMrHAuLmZmVjgXFzMzK5yLi5mZFc7FxczMCufiYmZmhXNxMTOzwrm4mJlZ4VxczMyscC4uZmZWuNKKi6S5krZKWldh32ckhaShaVuSZklqlrRG0km5tlMlbUjL1Fz8ZElr0zGzJCnFh0haktovkTS4rD6amVllZV653AxMaBuUdBQwHvh9LnwmMCot04EbU9shwJXAqcAY4MpcsbgRuDB3XOu5ZgD3RsQo4N60bWZmNVRacYmI+4HtFXbNBD4LRC42EbglMsuBQZKOAM4AlkTE9ojYASwBJqR9h0bE8ogI4Bbg7NxnzUvr83JxMzOrkZo+c5E0EdgSEb9ps2s4sDm33ZJiHcVbKsQBDo+IJ9P6U8DhHeQzXVKTpKZt27Z1tjtmZtaOmhUXSYcAnwO+WKtzpqua6GD/7IhojIjGYcOG1SotM7Ner5ZXLn8DjAR+I+lxYATwkKT/BmwBjsq1HZFiHcVHVIgD/DHdNiP93Fp4T8zMrEM1Ky4RsTYi3hARDRHRQHYr66SIeApYCExJo8bGAjvTra3FwHhJg9OD/PHA4rTvWUlj0yixKcCd6VQLgdZRZVNzcTMzq5EyhyLfDjwAvFlSi6RpHTRfBGwEmoHvARcBRMR24GpgZVquSjFSm++nY34H/DzFrwPeJ2kD8N60bWZmNdS/rA+OiMn72d+QWw/g4nbazQXmVog3AcdXiD8NjOtkumZmViB/Q9/MzArn4mJmZoVzcTEzs8K5uJiZWeFcXMzMrHAuLmZmVjgXFzMzK5yLi5mZFc7FxczMCufiYmZmhXNxMTOzwrm4mJlZ4VxczMyscC4uZmZWOBcXMzMrnIuLmZkVzsXFzMwKV+ZrjudK2ippXS72FUm/lbRG0k8kDcrtu0JSs6THJJ2Ri09IsWZJM3LxkZJWpPgPJQ1I8YFpuzntbyirj2ZmVlmZVy43AxPaxJYAx0fE24H/BK4AkDQamAQcl475jqR+kvoB3wbOBEYDk1NbgOuBmRFxLLADmJbi04AdKT4ztTMzsxoqrbhExP3A9jaxeyJiT9pcDoxI6xOB+RGxKyI2Ac3AmLQ0R8TGiNgNzAcmShLwHmBBOn4ecHbus+al9QXAuNTezMxqpJ7PXD4G/DytDwc25/a1pFh78dcDz+QKVWv8FZ+V9u9M7fchabqkJklN27Zt63aHzMwsU5fiIunzwB7gtnqcv1VEzI6IxohoHDZsWD1TMTPrVfrX+oSSzgc+AIyLiEjhLcBRuWYjUox24k8DgyT1T1cn+fatn9UiqT9wWGpvZmY1UtMrF0kTgM8CH4yIF3O7FgKT0kivkcAo4EFgJTAqjQwbQPbQf2EqSkuBc9LxU4E7c581Na2fA9yXK2JmZlYDpV25SLodOB0YKqkFuJJsdNhAYEl6xr48Ij4eEesl3QE8Qna77OKI2Js+5xJgMdAPmBsR69MpLgfmS7oGWA3MSfE5wK2SmskGFEwqq49mZlbZfouLpHOBuyPiOUlfAE4CromIhzo6LiImVwjPqRBrbX8tcG2F+CJgUYX4RrLRZG3jfwHO7Sg3MzMrVzW3xf5PKiynAe8lKxA3lpuWmZn1ZNUUl73p51nA7Ii4CxhQXkpmZtbTVVNctkj6LvBhYJGkgVUeZ2ZmfVQ1ReI8sgfqZ0TEM8AQ4LIykzIzs55tv8UlDRneCpyWQnuADWUmZWZmPdt+i4ukK8mG/V6RQq8GflBmUmZm1rNVc1vsQ8AHgRcAIuIPwOvKTMrMzHq2aorL7vQN9wCQ9JpyUzIzs56umuJyRxotNkjShcC/A98rNy0zM+vJ9vsN/Yj4qqT3Ac8Cbwa+GBFLSs/MzMx6rKrmFkvFxAXFzMyq0m5xkfQc6TlL211ARMShpWVlZmY9WrvFJSI8IszMzLqkqttikk4i+xJlAL+KiNWlZmVmZj1aNV+i/CIwj+w99EOBm9PU+2ZmZhVVc+XyEeCE9J4UJF0HPAxcU2JeZmbWg1XzPZc/AAfltgfyX++rNzMz20c1Vy47gfWSlpA9c3kf8KCkWQAR8akS8zMzsx6omiuXnwCfA5YCy4DPA3cCq9JSkaS5krZKWpeLDZG0RNKG9HNwikvSLEnNktakAQStx0xN7TdImpqLnyxpbTpmliR1dA4zM6udaqbcn9fR0sGhNwMT2sRmAPdGxCjg3rQNcCYwKi3TSa9RljQEuBI4FRgDXJkrFjcCF+aOm7Cfc5iZWY1UM1rsA5JWS9ou6VlJz0l6dn/HRcT9wPY24YlkI89IP8/OxW+JzHKyecyOAM4AlkTE9ojYQTZLwIS079CIWJ4m1bylzWdVOoeZmdVINc9cbgD+J7A2/SHvjsMj4sm0/hRweFofDmzOtWtJsY7iLRXiHZ1jH5Kmk10pcfTRR3e2L2Zm1o5qnrlsBtYVUFheIT+Nf1n2d46ImB0RjRHROGzYsDJTMTPrU6q5cvkssEjSL4BdrcGI+HoXzvdHSUdExJPp1tbWFN8CHJVrNyLFtgCnt4kvS/ERFdp3dA4zM6uRaq5crgVeJPuuy+tyS1csBFpHfE0lG3XWGp+SRo2NBXamW1uLgfGSBqcH+eOBxWnfs5LGplFiU9p8VqVzmJlZjVRz5XJkRBzf2Q+WdDvZVcdQSS1ko76uI3v52DTgCeC81HwR8H6gmayQXQAQEdslXQ2sTO2uiojWQQIXkY1IOxj4eVro4BxmZlYj1RSXRZLGR8Q9nfngiJjczq5xFdoGcHE7nzMXmFsh3gTsU/Qi4ulK5zAzs9qp5rbYJ4C7Jf25M0ORzcys76rmNcd+r4uZmXVKte9zGUz2Lfi/TmCZviRpZma2j/0WF0n/CFxKNtz3YWAs8ADwnlIzMzOzHquaZy6XAqcAT0TEu4G/BZ4pMykzM+vZqikuf8m9KGxgRPwWeHO5aZmZWU9WzTOXFkmDgJ8CSyTtIPv+iJmZWUXVjBb7UFr9kqSlwGHA3aVmZWZmPVo1U+7/jaSBrZtAA3BImUmZmVnPVs0zlx8BeyUdC8wmm2Dy30rNyszMerRqisvLEbEH+BDwzYi4DDii3LTMzKwnq6a4vCRpMtkMwz9LsVeXl5KZmfV01RSXC4B3ANdGxCZJI4Fby03LzMx6smpGiz0CfCq3vQm4vsykzMysZ6vmysXMzKxTXFzMzKxw7RYXSbemn5fWLh0zM+sNOrpyOVnSkcDH0jvsh+SX7pxU0j9JWi9pnaTbJR0kaaSkFZKaJf1Q0oDUdmDabk77G3Kfc0WKPybpjFx8Qoo1S5rRnVzNzKzzOiou/wrcC7wFWNVmaerqCSUNJxsg0BgRxwP9gElkgwRmRsSxwA5gWjpkGrAjxWemdkganY47DpgAfEdSP0n9gG8DZwKjgcmprZmZ1Ui7xSUiZkXEW4G5EXFMRIzMLcd087z9gYMl9SebSuZJsvfDLEj75wFnp/WJaZu0f5wkpfj8iNiVRrA1A2PS0hwRGyNiNzA/tTUzsxqpZijyJySdALwrhe6PiDVdPWFEbJH0VeD3wJ+Be8iuhp5JMwEAtADD0/pwYHM6do+kncDrU3x57qPzx2xuEz+1q/mamVnnVTNx5aeA24A3pOU2SZ/s6gnTK5MnAiOBI4HXkN3WqjlJ0yU1SWratm1bPVIwM+uVqnmfyz8Cp0bECwCSrid7zfE3u3jO9wKbImJb+rwfA+8EBknqn65eRgBbUvstZJNltqTbaIcBT+firfLHtBd/hYiYTTYZJ42NjdHF/piZWRvVfM9FwN7c9t4U66rfA2MlHZKenYwDHgGWAuekNlOBO9P6wrRN2n9fRESKT0qjyUYCo4AHgZXAqDT6bADZQ/+F3cjXzMw6qZorl5uAFZJ+krbPBuZ09YQRsULSAuAhYA+wmuzq4S5gvqRrUqz1HHOAWyU1A9vJigURsV7SHWSFaQ9wcUTsBZB0CbCYbCTa3IhY39V8zcys85RdBOynkXQScFra/GVErC41qzpobGyMpqYuj7A2K03DjLsqxh+/7qwaZ2K2L0mrIqKxbbyaKxci4iGyKw0zM7P98txiZmZWOBcXMzMrXIfFJU2nsrRWyZiZWe/QYXFJo69elnRYjfIxM7NeoJoH+s8DayUtAV5oDUbEp9o/xMzM+rJqisuP02JmZlaVaiaunCfpYODoiHisBjmZmVkPV83Elf8DeBi4O22fKMnTqZiZWbuqGYr8JbJ3pDwDEBEPA919n4uZmfVi1RSXlyJiZ5vYy2UkY2ZmvUM1D/TXS/p7oJ+kUWSvKP51uWmZmVlPVs2VyyfJ3lO/C7gdeBb4dIk5mZlZD1fNaLEXgc+nl4RFRDxXflpmZtaTVTNa7BRJa4E1ZF+m/I2kk8tPzczMeqpqnrnMAS6KiF8CSDqN7AViby8zMTMz67mqeeayt7WwAETEr8je/GhmZlZRu1cu6e2TAL+Q9F2yh/kBfBhYVn5qZmbWU3V05fK1tJwAvAm4kuwLlW8FTuzOSSUNkrRA0m8lPSrpHZKGSFoiaUP6OTi1laRZkpolrckVPSRNTe03SJqai58saW06ZpYkdSdfMzPrnHavXCLi3SWe9xvA3RFxjqQBwCHA54B7I+I6STOAGcDlwJnAqLScCtwInCppCFnBayS7ololaWFE7EhtLgRWAIuACcDPS+yPmZnl7PeBvqRBwBSgId++q1Pup3fD/B1wfvqc3cBuSROB01OzeWS33i4HJgK3REQAy9NVzxGp7ZKI2J4+dwkwQdIy4NCIWJ7itwBn4+JiZlYz1YwWWwQsB9ZSzLQvI4FtwE2STgBWAZcCh0fEk6nNU8DhaX04sDl3fEuKdRRvqRDfh6TpwHSAo48+uus9MjOzV6imuBwUEf+74HOeBHwyIlZI+gbZLbC/ioiQFAWes6KImA3MBmhsbCz9fGZmfUU1Q5FvlXShpCPSQ/ch6XlHV7UALRGxIm0vICs2f0y3u0g/t6b9W4CjcsePSLGO4iMqxM3MrEaqKS67ga8AD5DdwloFNHX1hBHxFLBZ0ptTaBzwCLAQaB3xNRW4M60vBKakUWNjgZ3p9tliYLykwWlk2Xhgcdr3rKSxaZTYlNxnmZlZDVRzW+wzwLER8acCz/tJ4LY0UmwjcAFZobtD0jTgCeC81HYR8H6gGXgxtSUitku6GliZ2l3V+nAfuAi4GTiY7EG+H+abmdVQNcWl9Y96YdILxxor7BpXoW0AF7fzOXOBuRXiTcDx3cvSzMy6qpri8gLwsKSlZNPuA10fimxmZr1fNcXlp2kxMzOrSjXvc5lXi0TMzKz3qOYb+pvIpld5hYg4ppSMzMysx6vmtlj+wftBwLlAd77nYmZmvdx+v+cSEU/nli0RcQNwVvmpmZlZT1XNbbGTcpuvIruSqeaKx8zM+qhqisTXcut7gMf5ry84mpmZ7aOa0WJlvtfFzMx6oWpuiw0E/hf7vs/lqvLSMjOznqya22J3AjvJJqzctZ+2ZmZmVRWXERExofRMzMys16hmyv1fS3pb6ZmYmVmvUc2Vy2nA+emb+rsAkU1W/PZSMzMzsx6rmuJyZulZmJlZr1LNUOQnapGImZn1HtU8czEzM+uUuhUXSf0krZb0s7Q9UtIKSc2SfphegYykgWm7Oe1vyH3GFSn+mKQzcvEJKdYsaUbNO2dm1sfV88rlUuDR3Pb1wMyIOBbYAUxL8WnAjhSfmdohaTQwCTgOmAB8JxWsfsC3yZ4VjQYmp7ZmZlYjdSkukkaQzaz8/bQt4D3AgtRkHnB2Wp+Ytkn7x6X2E4H5EbErIjYBzcCYtDRHxMaI2A3MT23NzKxG6nXlcgPwWeDltP164JmI2JO2W4DhaX04sBkg7d+Z2v813uaY9uJmZlYjNS8ukj4AbI2IVbU+d4VcpktqktS0bdu2eqdjZtZr1OPK5Z3AByU9TnbL6j3AN4BBklqHRo8AtqT1LcBRAGn/YcDT+XibY9qL7yMiZkdEY0Q0Dhs2rPs9MzMzoA7FJSKuiIgREdFA9kD+voj4CLAUOCc1m0o2YSbAwrRN2n9fRESKT0qjyUYCo4AHgZXAqDT6bEA6x8IadM3MzJID6Y2SlwPzJV0DrAbmpPgc4FZJzcB2smJBRKyXdAfwCNlLzC6OiL0Aki4BFgP9gLkRsb6mPTEz6+PqWlwiYhmwLK1vJBvp1bbNX4Bz2zn+WuDaCvFFwKICUzUzs07wN/TNzKxwLi5mZlY4FxczMyuci4uZmRXOxcXMzArn4mJmZoVzcTEzs8K5uJiZWeFcXMzMrHAuLmZmVjgXFzMzK5yLi5mZFc7FxczMCufiYmZmhXNxMTOzwrm4mJlZ4VxczMyscC4uZmZWuJoXF0lHSVoq6RFJ6yVdmuJDJC2RtCH9HJzikjRLUrOkNZJOyn3W1NR+g6SpufjJktamY2ZJUq37aWbWl9XjymUP8JmIGA2MBS6WNBqYAdwbEaOAe9M2wJnAqLRMB26ErBgBVwKnAmOAK1sLUmpzYe64CTXol5mZJTUvLhHxZEQ8lNafAx4FhgMTgXmp2Tzg7LQ+EbglMsuBQZKOAM4AlkTE9ojYASwBJqR9h0bE8ogI4JbcZ5mZWQ3U9ZmLpAbgb4EVwOER8WTa9RRweFofDmzOHdaSYh3FWyrEK51/uqQmSU3btm3rXmfMzOyv6lZcJL0W+BHw6Yh4Nr8vXXFE2TlExOyIaIyIxmHDhpV9OjOzPqMuxUXSq8kKy20R8eMU/mO6pUX6uTXFtwBH5Q4fkWIdxUdUiJuZWY3UY7SYgDnAoxHx9dyuhUDriK+pwJ25+JQ0amwssDPdPlsMjJc0OD3IHw8sTvuelTQ2nWtK7rPMzKwG+tfhnO8E/gFYK+nhFPsccB1wh6RpwBPAeWnfIuD9QDPwInABQERsl3Q1sDK1uyoitqf1i4CbgYOBn6fFzMxqpObFJSJ+BbT3vZNxFdoHcHE7nzUXmFsh3gQc3400zcysG/wNfTMzK5yLi5mZFc7FxczMCufiYmZmhXNxMTOzwrm4mJlZ4VxczMyscC4uZmZWOBcXMzMrnIuLmZkVzsXFzMwK5+JiZmaFc3ExM7PCubiYmVnhXFzMzKxwLi5mZlY4FxczMyuci4uZmRWu1xYXSRMkPSapWdKMeudjZtaX9MriIqkf8G3gTGA0MFnS6PpmZWbWd/TK4gKMAZojYmNE7AbmAxPrnJOZWZ/Rv94JlGQ4sDm33QKc2raRpOnA9LT5vKTHapBb0YYCf6p3EjXU1/oL7fRZ19chk9rx77nneGOlYG8tLlWJiNnA7Hrn0R2SmiKisd551Epf6y+4z31Fb+tzb70ttgU4Krc9IsXMzKwGemtxWQmMkjRS0gBgErCwzjmZmfUZvfK2WETskXQJsBjoB8yNiPV1TqssPfq2Xhf0tf6C+9xX9Ko+KyLqnYOZmfUyvfW2mJmZ1ZGLi5mZFc7F5QAmqZ+k1ZJ+1iY+S9LzHRz3dkkPSFovaa2kg8rPthhd6bOkV0ual/r6qKQrapNtMdr2WdLNkjZJejgtJ7Zz3FRJG9IytaZJd1NX+izpxNz/r9dI+nDNE++irv6OU9tDJbVI+lbNEi5Ar3yg34tcCjwKHNoakNQIDG7vAEn9gR8A/xARv5H0euClshMtUKf7DJwLDIyIt0k6BHhE0u0R8XipmRZnnz4Dl0XEgvYOkDQEuBJoBAJYJWlhROwoNdPidLrPwIvAlIjYIOlIsj4vjohnSsyzKF3pb6urgftLyapEvnI5QEkaAZwFfD8X6wd8BfhsB4eOB9ZExG8AIuLpiNhbZq5F6UafA3hNKqwHA7uBZ0tMtTCV+lylM4AlEbE9FZQlwISi8ytDV/scEf8ZERvS+h+ArcCw4jMsVjd+x0g6GTgcuKfovMrm4nLguoHsD+rLudglwMKIeLKD494EhKTFkh6S1NEf5QPNDXStzwuAF4Angd8DX42I7WUlWbAb2LfPANemWz8zJQ2scFylKY6Gl5Ni4W6ga33+K0ljgAHA78pJsVA30IX+SnoV8DXgn8tPsXguLgcgSR8AtkbEqlzsSLLbP9/cz+H9gdOAj6SfH5I0rqxci9LNPo8B9gJHAiOBz0g6pqxci1Kpz8kVwFuAU4AhwOW1zq0sRfRZ0hHArcAFEdH2D/YBpZv9vQhYFBEt5WZZDj9zOTC9E/igpPcDB5Hdp10P7AKaJQEcIqk5Io5tc2wLcH9E/AlA0iLgJODeWiXfRd3p898Dd0fES8BWSf9B9ixiY82y75p9+izpBxHx0bR/l6SbqPwv1y3A6bntEcCyEnMtSnf6jKRDgbuAz0fE8ppk3D3d6e87gHdJugh4LTBA0vMR0TPeTxURXg7ghewPyM8qxJ9vp/1g4CHgELJ/PPw7cFa9+1Fyny8HbkrrrwEeAd5e7350tc/AEemnyG6pXFeh/RBgU/p9D07rQ+rdj5L7PIDsH0mfrnfutehvm2PPB75V7z50ZvFtsV5A0gclXQUQ2cPdr5PNr/Yw8FBE3FXH9EqR7zPZi+FeK2k9Wb9viog19cuu226TtBZYSzYN+zWQjZqT9H2AyJ4pXU3W35XAVdFznjNVst8+A+cBfwecX80Q3gNcNf3t0Tz9i5mZFc5XLmZmVjgXFzMzK5yLi5mZFc7FxczMCufiYmZmhXNxsT6pvRmWu/mZJ6Yvy7Vuf0lSl6fukHRumuV5aTEZdjmPxyUNrWcO1vO4uJgV50Tg/ftr1AnTgAsj4t0FfqZZTbi4WJ8n6TJJK9Mkgv+SYg3pquF76f0h90g6OO07JbV9WNJXJK2TNAC4Cvhwire+a2S0pGWSNkr6VDvnn6zsXTTrJF2fYl8kmxtujqSvtGl/hKT703nWSXpXit8oqSnl+y+59o9L+nJq3yTppDSx6e8kfTy1OT195l2SHpP0r2nixLa5flTSg+mzvqvsPSX9lL2fZF3qxz9181divUG9pwjw4qUeC2kqGbJXFMwmm4bjVcDPyL4F3gDsAU5M7e4APprW1wHvSOvXAevS+vnkpugAvgT8GhhI9i3sp4FXt8njSLKZnIeRTddzH3B22rcMaKyQ+2fI5tYC6Ae8Lq0PycWWkabAAR4HPpHWZwJrgNelc/4xxU8H/gIck45fApyTO34o8Fbg/7X2AfgOMAU4mWz6/9b8BtX79+ul/ouvXKyvG5+W1WRzsr0FGJX2bYqIh9P6KqBB0iCyP+YPpPi/7efz74qIXZFNJLqV7N0ceacAyyJiW0TsAW4jK24dWQlcIOlLwNsi4rkUP0/SQ6kvxwGjc8csTD/XAisi4rmI2EY2ceKgtO/BiNgY2ft/bie7csobR1ZIVkp6OG0fQzZB6DGSvilpAj3kXTpWLs+KbH2dgC9HxHdfEZQayGZkbrWX7EVkndX2M7r931xE3C/p78heQHWzpK8DvySbWfeUiNgh6WayWXjb5vFym5xezuXUdi6ottsC5kXEPq+RlnQC2QvMPk42B9jHOtsv61185WJ93WLgY5JeCyBpuKQ3tNc4slfqPifp1BSalNv9HNntps54EPjvkoYqe+vmZOAXHR0g6Y1kt7O+R/Z2w5PIXlHwArBT0uHAmZ3MA2CMpJHpWcuHgV+12X8vcE7r/z6Shkh6YxpJ9qqI+BHwhZSP9XG+crE+LSLukfRW4AFl74x5Hvgo2VVGe6YB35P0Mlkh2JniS4EZ6ZbRl6s8/5OSZqRjRXYb7c79HHY6cJmkl1K+UyJik6TVwG/J3lD5H9Wcv42VwLeAY1M+P2mT6yOSvgDckwrQS8DFwJ+Bm3IDAPa5srG+x7Mim3WSpNdGxPNpfQbZuzkurXNa3SLpdOCfI+IDdU7FeglfuZh13lmSriD77+cJslFiZpbjKxczMyucH+ibmVnhXFzMzKxwLi5mZlY4FxczMyuci4uZmRXu/wN8LG0xEijqUwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('문장의 최대 길이 :',max(len(l) for l in X_train)) # 단어의 수\n",
    "print('문장의 평균 길이 :',sum(map(len, X_train1))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 100)         2248700   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 128)         117248    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,465,149\n",
      "Trainable params: 2,465,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2300 - acc: 0.6252\n",
      "Epoch 1: val_acc improved from -inf to 0.73128, saving model to bilstm.h5\n",
      "21/21 [==============================] - 139s 7s/step - loss: 0.2300 - acc: 0.6252 - val_loss: 0.1838 - val_acc: 0.7313\n",
      "Epoch 2/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1472 - acc: 0.7955\n",
      "Epoch 2: val_acc improved from 0.73128 to 0.81363, saving model to bilstm.h5\n",
      "21/21 [==============================] - 126s 6s/step - loss: 0.1472 - acc: 0.7955 - val_loss: 0.1321 - val_acc: 0.8136\n",
      "Epoch 3/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1129 - acc: 0.8480\n",
      "Epoch 3: val_acc improved from 0.81363 to 0.82768, saving model to bilstm.h5\n",
      "21/21 [==============================] - 135s 6s/step - loss: 0.1129 - acc: 0.8480 - val_loss: 0.1219 - val_acc: 0.8277\n",
      "Epoch 4/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0993 - acc: 0.8685\n",
      "Epoch 4: val_acc did not improve from 0.82768\n",
      "21/21 [==============================] - 87s 4s/step - loss: 0.0993 - acc: 0.8685 - val_loss: 0.1222 - val_acc: 0.8276\n",
      "Epoch 5/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0923 - acc: 0.8785\n",
      "Epoch 5: val_acc did not improve from 0.82768\n",
      "21/21 [==============================] - 126s 6s/step - loss: 0.0923 - acc: 0.8785 - val_loss: 0.1246 - val_acc: 0.8264\n",
      "Epoch 6/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0871 - acc: 0.8875\n",
      "Epoch 6: val_acc improved from 0.82768 to 0.83056, saving model to bilstm.h5\n",
      "21/21 [==============================] - 87s 4s/step - loss: 0.0871 - acc: 0.8875 - val_loss: 0.1225 - val_acc: 0.8306\n",
      "Epoch 7/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0831 - acc: 0.8941\n",
      "Epoch 7: val_acc did not improve from 0.83056\n",
      "21/21 [==============================] - 84s 4s/step - loss: 0.0831 - acc: 0.8941 - val_loss: 0.1277 - val_acc: 0.8279\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('bilstm.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=6000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 29s 18ms/step - loss: 0.1206 - acc: 0.8372\n",
      "\n",
      " 테스트 정확도: 0.8372\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('bilstm.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "from konlpy.tag import Okt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "okt = Okt()\n",
    "stopwords = a\n",
    "loaded_model = load_model('bilstm.h5')\n",
    "max_len = 42\n",
    "\n",
    "global corpus\n",
    "global avg_emo\n",
    "global score\n",
    "\n",
    "corpus = []\n",
    "avg_emo = 0\n",
    "\n",
    "\n",
    "heal = ['여수 밤바다', '파주 평화누리공원', '순천 갈대밭', '제주도 영실코스', \n",
    "         '진주 진양호', '장흥유원지', '대구 앞산정만대', '춘천 해피초원농장' ,' 속초 해수욕장', \n",
    "         '경주 불국사', '포항 호미곶', '남해 두모마을', '대관령 하늘목장', '군산 철길마을', \n",
    "         '국립 광릉수목원', '금선사 템플스테이', '보성 제암산자연휴양림','군산 선유도']\n",
    " \n",
    "extreme= ['통영 어드벤처 타워', '제주도  스쿠버다이빙', '단양 패러글라이딩', \n",
    "          '강원 내린천 래프팅', '충주 스카이다이빙', '하남 스포츠몬스터', '서울 한강 워터 제트팩', \n",
    "          '일산 인공 서핑', '영월 동강래프팅', '여수 스카이플라이', '문경 패러글라이딩', \n",
    "          '경남 하동 하동알프스레포츠', '인천 스카이 짚라인', '강화 루지']\n",
    " \n",
    "movie=['루카','콰이어트 플레이스','크루엘라','컨저링 3:악마가 시켰다','여고괴담 여섯번째 이야기','분노의 질주: 더 얼티메이트','캐시트럭',\n",
    "'클라이밍',\n",
    "'그 여름, 가장 차가웠던',\n",
    "'폭력의 그림자',\n",
    "'청춘 선거',\n",
    "'그레타 툰베리',\n",
    "'낫아웃',\n",
    "'마세티 킬즈',\n",
    "'프로페서 앤 매드맨',\n",
    "'화이트 온 화이트',\n",
    "'아야와 마녀',\n",
    "'까치발',\n",
    "'플래시백',\n",
    "'애플',\n",
    "'혼자 사는 사람들',\n",
    "'강호아녀',\n",
    "'파이프라인',\n",
    "'분노의 질주']\n",
    " \n",
    "#음악 (네이버 바이브 참고 1위~20위)\n",
    " \n",
    "k_balad=['Timeless-SG워너비',\n",
    "'추적이는 여름 비가 되어-장범준',\n",
    "'밤하늘의 별을 (2020)-경서',\n",
    "'어떻게 이별까지 사랑하겠어, 널 사랑하는 거지-AKMU (악동뮤지션)',\n",
    "'내 입술 따뜻한 커피처럼-청하 Colde(콜드)',\n",
    "'서울의 잠 못 이루는 밤 (Feat. 이수현)-10CM',\n",
    "'잠이 오질 않네요-장범준',\n",
    "'I Love U-성시경',\n",
    "'내사람 (Partner For Life)-SG워너비',\n",
    "'취기를 빌려-산들',\n",
    "'안녕 (Hello)-조이',\n",
    "'밤편지-아이유(IU)',\n",
    "'Anti-Romantic-투모로우바이투게더',\n",
    "'너의 모든 순간-성시경',\n",
    "'좋을텐데 (If Only) (Feat. 폴킴)-조이',\n",
    "'봄 안녕 봄-아이유(IU)',\n",
    "'Love poem -아이유(IU)',\n",
    "'아이와 나의 바다-아이유(IU)',\n",
    "'벌써 일년-반하나& MJ(써니사이드)',\n",
    "'이렇게 좋아해 본 적이 없어요 -CHEEZE (치즈)'\n",
    "]\n",
    " \n",
    "k_dance=[\n",
    "'Butter-방탄소년단',\n",
    "'Next Level-aespa',\n",
    "'Dun Dun Dance-오마이걸(OH MY GIRL)',\n",
    "'치맛바람 (Chi Mat Ba Ram)-브레이브걸스(Brave Girls)',\n",
    "'Alcohol-Free-TWICE(트와이스)',\n",
    "\"롤린 (Rollin')-브레이브걸스(Brave Girls)\",\n",
    "'라일락-아이유(IU)',\n",
    "'ASAP-STAYC(스테이씨)',\n",
    "'Dynamite-방탄소년단',\n",
    "'상상더하기-MSG워너비',\n",
    "'Celebrity-아이유(IU)',\n",
    "'상상더하기-라붐(LABOUM)',\n",
    "'Ready to love-세븐틴',\n",
    "'Dolphin-오마이걸(OH MY GIRL)',\n",
    "'Lovesick Girls-BLACKPINK',\n",
    "'Pool Party (Feat. 이찬 of DKB)-브레이브걸스(Brave Girls)',\n",
    "\"Heaven's Cloud-세븐틴\",\n",
    "'체념-정상동기(김정수, 정기석, 이동휘, 이상이)',\n",
    "'어푸 (Ah puh)-아이유(IU)',\n",
    "]\n",
    " \n",
    "k_hip=[\n",
    "'마.피.아. In the morning-ITZY(있지)',\n",
    "'봄날-방탄소년단',\n",
    "'Life Goes On-방탄소년단',\n",
    "'맛 (Hot Sauce)-NCT DREAM',\n",
    "'밸런스 게임-투모로우바이투게더',\n",
    "'GAM3 BO1-세븐틴',\n",
    "'비도 오고 그래서 (Feat. 신용재)-헤이즈 (Heize)',\n",
    "'METEOR-창모(CHANGMO)',\n",
    "'DNA-방탄소년단',\n",
    "'IDOL-방탄소년단',\n",
    "'FAKE LOVE-방탄소년단',\n",
    "'피 땀 눈물-방탄소년단',\n",
    "'사이렌-호미들',\n",
    "'멜로디-ASH ISLAND',\n",
    "'I NEED U-방탄소년단',\n",
    "'아무노래-지코 (ZICO)',\n",
    "'어떻게 지내 (Prod. By VAN.C)-오반(OVAN)',\n",
    "'Rainy day (Feat. ASH ISLAND, Skinny Brown)-PATEKO(파테코)',\n",
    "'뚜두뚜두 (DDU-DU DDU-DU)-BLACKPINK']\n",
    " \n",
    " \n",
    "trt=[\n",
    "'이제 나만 믿어요-임영웅',\n",
    "'별빛 같은 나의 사랑아-임영웅',\n",
    "'다시 사랑한다면 (김필 Ver.)-임영웅',\n",
    "'HERO-임영웅',\n",
    "'미워요-임영웅',\n",
    "'잊어야 한다는 마음으로-임영웅',\n",
    "'계단말고 엘리베이터-임영웅',\n",
    "'소나기-임영웅',\n",
    "'바보같지만-임영웅',\n",
    "'따라따라-임영웅',\n",
    "'당신-임영웅',\n",
    "'내 마음 별과 같이-임영웅',\n",
    "'고맙소-김호중',\n",
    "'만개 (Prod. 신지후)-김호중',\n",
    "'나보다 더 사랑해요-김호중',\n",
    "'애인이 되어줄게요 (Prod. 알고보니, 혼수상태)-김호중',\n",
    "'퇴근길-김호중',\n",
    "'할무니-김호중',\n",
    "'우산이 없어요-김호중',\n",
    "'천년의 사랑-김호중'\n",
    "]\n",
    " \n",
    " \n",
    "f_dance=[\n",
    "'You-Regard, Troye Sivan, Tate McRae',\n",
    "'Closer (Feat. Halsey)-The Chainsmokers',\n",
    "'Faded-Alan Walker',\n",
    "'One Kiss-Calvin Harris, Dua Lipa',\n",
    "'Heartbreak Anthem-Galantis, David Guetta, Little Mix',\n",
    "'Something Just Like This-The Chainsmokers, Coldplay',\n",
    "'This Is What You Came For (Feat. Rihanna)-Calvin Harris',\n",
    "'The Middle-Zedd, Grey, Maren Morris',\n",
    "'Symphony (Feat. Zara Larsson)-Clean Bandit',\n",
    "'Wake Me Up-Avicii',\n",
    "'Waste It On Me (Feat. BTS(방탄소년단))-Steve Aoki',\n",
    "'How To Love (Feat. Sofia Reyes)-Cash Cash',\n",
    "'Bad Boy (with Wiz Khalifa, bbno$, MAX)-Yung Bae, Wiz Khalifa, bbno$, MAX',\n",
    "'Titans (Feat. Sia & Labrinth) (Imanbek Remix)-Major Lazer',\n",
    "'Feels (Feat. Pharrell Williams, Katy Perry, Big Sean)-Calvin Harris',\n",
    "'Rise (Feat. Jack & Jack)-Jonas Blue',\n",
    "'Mama (Feat. William Singe)-Jonas Blue',\n",
    "'Just Got Paid (Feat. French Montana)-Sigala, Ella Eyre, Meghan Trainor',\n",
    "'Love Line-Shift K3y, Tinashe',\n",
    "'Lonely Together (Feat. Rita Ora)-Avicii'\n",
    "]\n",
    " \n",
    "newage=[\n",
    "'River Flows In You-이루마',\n",
    "'Letter From The Earth (지구에서 온 편지)-김광민',\n",
    "'익숙한 그 집 앞-유희열',\n",
    "'처음부터 지금까지 (Inst.)-박정원',\n",
    "'냉정과 열정 사이 OST (冷靜と情熱のあいだ)-Ryo Yoshimata',\n",
    "'''Tomorrow's Promise-Kevin Kern''',\n",
    "\"Mia & Sebastian's Theme-Justin Hurwitz\",\n",
    "'Recuerods de la Alhambra (알함브라 궁전의 추억)-Claude Ciari',\n",
    "'''Gabriel's Oboe-Ennio Morricone''',\n",
    "'Rain-Ryuichi Sakamoto',\n",
    "'Romance-Yuhki Kuramoto',\n",
    "'Second Romance-Yuhki Kuramoto',\n",
    "'Crystal Rainbow-데이드림(Daydream)',\n",
    "'My Road (Live)-Lee Oskar',\n",
    "'Last Carnival-Acoustic Cafe',\n",
    "'Return To The Heart-David Lanz',\n",
    "'Adagio-Secret Garden',\n",
    "'Loving You-Kenny G'\n",
    "]\n",
    "\n",
    "korean = [\"삼계탕\", \"삼겹살\", \"곱창\", \"찜닭\", \"오리고기\", \"소고기\", \n",
    "          \"국밥\", \"닭도리탕\", \"낙곱새\", \"라면\", \"비빔밥\", \"칼국수\", \n",
    "          \"수제비\", \"갈비\", \"제육볶음\"]\n",
    "\n",
    "western = [\"스테이크\", \"파스타\", \"필라프\", \"감바스\", \"리조또\", \"샐러드\", \n",
    "           \"피자\", \"빠에야\", \"플래터\", \"스튜\"]\n",
    "\n",
    "asian = [\"짜장면\", \"뿌팟퐁커리\", \"팟타이\", \"나시고랭\", \"쌀국수\", \"미고랭\",\n",
    "         \"카레\", \"마라탕\", \"마라샹궈\", \"훠궈\", \"돈까스\", \"월남쌈\", \"라멘\", \n",
    "         \"탄탄멘\", \"규동\", \"꿔바로우\", \"똠양꿍\", \"물냉면\"]\n",
    "\n",
    "spicy = [\"떡볶이\", \"김치찜\", \"김치찌개\", \"감자탕\", \"짬뽕\", \"닭발\", \"부대찌개\",\n",
    "         \"순두부찌개\", \"아구찜\", \"해물찜\", \"육개장\", \"낙지볶음\", \"쭈꾸미\", \n",
    "         \"돼지갈비찜\", \"소꼬리찜\", \"비빔냉면\"]\n",
    "\n",
    "dessert = [\"와플\", \"마카롱\", \"빙수\", \"크로크모슈\", \"케이크\", \"허니바게트볼\",\n",
    "           \"머쉬룸수프볼\", \"에그데니쉬\", \"케이크\", \"치아바타\", \"호두파운드케이크\",\n",
    "           \"쿠키\", \"허니브레드\", \"오믈렛\", \"베이글\"]\n",
    "\n",
    "snack = [\"닭강정\", \"양꼬치\", \"핫윙\", \"소떡소떡\", \"가라아게\", \"콘치즈\", \"감자튀김\", \n",
    "         \"치킨너겟\", \"치킨\", \"낫쵸\", \"소시지\", \"버터구이\", \"계란찜\", \"핫도그\", \n",
    "         \"해쉬브라운\"]\n",
    "\n",
    "coffee = [\"아메리카노\", \"콜드브루\", \"바닐라 라떼\", \"카페 라떼\", \"카라멜 마키아또\",\n",
    "          \"카페 모카\", \"바닐라 프라페\", \"카페모카 프라페\", \"연유 라떼\", \"화이트 모카\",\n",
    "          \"민트 모카\", \"헤이즐넛 라떼\", \"에스프레소\", \"오곡 프라페\", \"쿠앤크 프라페\"]\n",
    "\n",
    "beverage = [\"초코 라떼\", \"민트초코 라떼\", \"밀크티\", \"흑당 버블티\", \"레몬차\", \"자몽차\",\n",
    "            \"유자차\", \"모히토\", \"요거트 스무디\", \"블루베리 스무디\", \"딸기 스무디\", \"애플망고 스무디\",\n",
    "            \"레몬 에이드\", \"자몽 에이드\", \"생과일 주스\"]\n",
    "\n",
    "motivation = [\"자신을 믿어라. 자신의 능력을 신뢰하라. 겸손하지만 합리적인 자신감 없이는 성공할 수도 행복할 수도 없다. - 노먼 빈센트 필\",\n",
    "\"조금 더 많이 인내하자. 조금 더 많이 노력하자. 그러면 절망적 실패로 보였던 것이 빛나는 성공으로 변할 수 있다. - 알버트 휴버드\",\n",
    "\"당신이 인생의 주인공이기 때문이다. 그 사실을 잊지말라. 지금까지 당신이 만들어온 의식적 그리고 무의식적 선택으로 인해 지금의 당신이 있는것이다. - 바바라 홀\",\n",
    "\"먹는 칼로리보다 에너지 소모가 적으면 살이 찌듯이, 걱정만 하고 행동하지 않으면 걱정이 찐다.\",\n",
    "\"이미 끝나버린 일을 후회하기 보다는 하고 싶었던 일을 하지 못한 것을 후회하라 - 탈무드\",\n",
    "\"기회가 주어지면 최선을 다하는 것이 아니라 최선을 다하고 있으면 기회가 주어지는 것이다 - 신영준\",\n",
    "\"낭비한 시간에 대한 후회는 더 큰 시간 낭비이다 - 메이슨 쿨리\",\n",
    "\"성공은 매일 부단하게 반복된 작은 노력의 합산이다.\",\n",
    "\"현명한 사람은 앉아서 손해 본 것을 한탄만 하지 않고 즐겁게 그 손해를 회복할 방법을 찾는다. - 셰익스피어\",\n",
    "\"고통을 주지 않는것은 쾌락도 주지 않는다 - 몽테뉴\",\n",
    "\"시간은 간다\",\n",
    "\"살아가는 사람들 중 대부분은 자신에게 올 기회를 기다리나 기회라는 것은 기다리는 사람에게는 쉽게 오지 않는 법이다\",\n",
    "\"기회를 얻을 수 있게 기다리는 사람이 되기보다는 기회를 얻을 수 있는 실력을 먼저 쌓아야 한다. 자신이 하는 일에 열중하고 노력하다보면 자연스럽게 기회는 찾아온다.\",\n",
    "\"변화를 위해서 가장 중요한 것은 행동하는 첫걸음이다.\",\n",
    "\"무엇이든 하루아침에 만들어지는 것은 없다. 로마 또한 하루아침에 만들어지지 않았다. 이 말은 무언가를 만들기 위해서는 그것을 만들기 위해 노력하고 집중 해야 한다는 것이다.\",\n",
    "\"스스로를 믿고 자신이 가지고 있는 능력을 신뢰해야 한다. 하지만 거만하게 행동하지 말고 겸손해라. 성공을 위해서 자신감이 필요하지만 오만함은 필요하지 않다.\",\n",
    "             \"끝난 일은 언급할 필요가 없으며 지난 일은 허물을 물을 필요가 없다. - 공자\",\n",
    "\"어렵고 힘든 상황일수록 서두르지 말고 침착해라. 성급하게 하는 행동에는 실수가 포함되기 쉽다.\",\n",
    "\"나의 하루를 설명할 수 있는 사람이 곁에 있다는 건 생각보다 기분 좋은 일이야 그러니 너도 생각보다 좋은 사람이지 - 흔글\",\n",
    "\"잠 못 자고 있지, 얼른 자, 걱정하는 일 안 생겨 좋은 일은 아니더라도 아무 일 없을 거야 혼자 있는 새벽을 걱정으로 보내지는 마 - 흔글\",\n",
    "\"봄바람도 살랑살랑 불고 꽃도 예쁘게 피어있으니 얼마나 놀고 싶겠냐만은, 그래도 그 시간들을 이겨내면 너의 인생에 꽃이 필 테니 조금만 참고 바람을 이겨내기를 - 흔글\"]\n",
    "\n",
    "category = [heal,extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f8 = [extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f6 = [extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f3 = [heal,extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage, dessert]\n",
    "f1 = [heal,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage, dessert]\n",
    "f0 = [heal,movie,k_balad,k_dance,k_hip,f_dance,newage,korean,western,asian,spicy,spicy,dessert,snack,snack,coffee,beverage]\n",
    "\n",
    "def recomend_sys(new_sentence):\n",
    "    global score\n",
    "    global timecheck\n",
    "    global corpus\n",
    "    global score\n",
    "    global avg_emo\n",
    "\n",
    "    print(new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new)) # 예측\n",
    "    \n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))\n",
    "        \n",
    "    corpus.append(score)\n",
    "    if len(corpus) >= 5:\n",
    "        avg_emo = sum(corpus)/len(corpus)\n",
    "        if(avg_emo > 0.8):\n",
    "            pick = random.choice(f8)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘처럼 좋은 날엔 {0} 어떠신가요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "\n",
    "        elif(avg_emo > 0.6): \n",
    "            pick = random.choice(f6)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"좋은 일있으신가요? 오늘 {0} 어떠세요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.4) :\n",
    "            pick = random.choice(category)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘같은 날에는 {0} 어때요? 기분이 좋아질거에요!!\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.3) :\n",
    "            pick = random.choice(f3)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"꿀꿀한 오늘 {0} 추천해요.\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.18) :\n",
    "            pick = random.choice(f1)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘 {0} 어떠세요? 안좋은 기분을 환기시켜줄 거에요.\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        else:\n",
    "            pick = random.choice(f0)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘 안좋은 일이 있으셨나요. 오늘같은 날 {0} 어떠세요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "    else:\n",
    "        print('감정 분석까지 {0}개의 문장이 남았어요!'.format(5-len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "석정이는 종원이를 좋아해\n",
      "82.31% 확률로 긍정 리뷰입니다.\n",
      "\n",
      "감정 분석까지 4개의 문장이 남았어요!\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 재밌다 ㅋㅋㅋㅋㅋ 사실 거짓말임\n",
      "80.03% 확률로 부정 리뷰입니다.\n",
      "\n",
      "감정 분석까지 2개의 문장이 남았어요!\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "담배 마렵다\n",
      "61.05% 확률로 부정 리뷰입니다.\n",
      "\n",
      "감정 분석까지 1개의 문장이 남았어요!\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이게 영화냐 신의 기술이지\n",
      "93.38% 확률로 긍정 리뷰입니다.\n",
      "\n",
      "기분 점수 : 62.03\n",
      "좋은 일있으신가요? 오늘 콘치즈 어떠세요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이런류의 영화는 이제 안나왔으면 좋겠다\n",
      "82.03% 확률로 부정 리뷰입니다.\n",
      "\n",
      "기분 점수 : 50.50\n",
      "오늘같은 날에는 치킨너겟 어때요? 기분이 좋아질거에요!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recomend_sys(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2c46c1df1dd7a671db094ae67dcdb68f5eec724ea0466823b5d20033f2bee27"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('conda37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
