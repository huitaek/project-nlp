{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 사용 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.jvm import init_jvm # JVM을 초기화하는 함수 init_jvm을 제공\n",
    "\n",
    "from pykospacing import Spacing # 한글 띄어쓰기 라이브러리\n",
    "from hanspell import spell_checker # 한글 맞춤법 라이브러리\n",
    "from tqdm import tqdm # 진행상황 Progress Bar를 위한 tqdm library\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        50000 non-null  int64 \n",
      " 1   document  49997 non-null  object\n",
      " 2   label     50000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "train_data = pd.read_table('./data/ratings_train.txt')\n",
    "test_data = pd.read_table('./data/ratings_test.txt')\n",
    "\n",
    "# 데이터 확인\n",
    "\n",
    "print(train_data.info())# 150000 row\n",
    "print(test_data.info()) # 50000 row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 중복값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data id 중복값:  0\n",
      "train_data document 중복값:  3812\n",
      "train_data label 값:  [0 1] \n",
      "\n",
      "test_data id 중복값:  0\n",
      "test_data document 중복값:  839\n",
      "test_data label 값:  [1 0] \n",
      "\n",
      "train data 개수:  146183\n",
      "test_data 개수:  49158\n"
     ]
    }
   ],
   "source": [
    "# train_data 중복값 확인\n",
    "\n",
    "print('train_data id 중복값: ', train_data['id'].notnull().sum() - len(train_data['id'].unique()))\n",
    "print('train_data document 중복값: ', train_data['document'].notnull().sum() - len(train_data['document'].unique()))\n",
    "\n",
    "print('train_data label 값: ', train_data['label'].unique(), '\\n') # 0, 1\n",
    "\n",
    "# test_data 중복값 확인\n",
    "\n",
    "print('test_data id 중복값: ', test_data['id'].notnull().sum() - len(test_data['id'].unique()))\n",
    "print('test_data document 중복값: ', test_data['document'].notnull().sum() - len(test_data['document'].unique()))\n",
    "\n",
    "print('test_data label 값: ', test_data['label'].unique(), '\\n') # 0, 1\n",
    "\n",
    "# 중복값 제거\n",
    "\n",
    "train_data.drop_duplicates(['document'], inplace=True)\n",
    "test_data.drop_duplicates(['document'], inplace=True)\n",
    "\n",
    "print('train data 개수: ', len(train_data))\n",
    "print('test_data 개수: ', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 구두점, 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-152f18873e90>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','') # [ㄱ - ㅎ, ㅏ - ㅣ, 가 - 핳] 제외 제거\n",
      "<ipython-input-67-152f18873e90>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('^ +', '') # 화이트 스페이스 제거\n",
      "<ipython-input-67-152f18873e90>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','')\n",
      "<ipython-input-67-152f18873e90>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('^ +', '')\n"
     ]
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','') # [ㄱ - ㅎ, ㅏ - ㅣ, 가 - 핳] 제외 제거\n",
    "train_data['document'] = train_data['document'].str.replace('^ +', '') # 화이트 스페이스 제거\n",
    "\n",
    "test_data['document'] = test_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','')\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4221289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9509970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>10147571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>7117896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>6478189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149309</th>\n",
       "      <td>6715725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149358</th>\n",
       "      <td>6780491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149364</th>\n",
       "      <td>8014701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149630</th>\n",
       "      <td>3508604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149773</th>\n",
       "      <td>9233162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>790 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id document  label\n",
       "404      4221289      NaN      0\n",
       "412      9509970      NaN      1\n",
       "470     10147571      NaN      1\n",
       "584      7117896      NaN      0\n",
       "593      6478189      NaN      0\n",
       "...          ...      ...    ...\n",
       "149309   6715725      NaN      1\n",
       "149358   6780491      NaN      0\n",
       "149364   8014701      NaN      1\n",
       "149630   3508604      NaN      0\n",
       "149773   9233162      NaN      0\n",
       "\n",
       "[790 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "\n",
    "\n",
    "print(len(train_data[train_data['document']==\"\"]), train_data['document'].isnull().sum()) # 비어있는 값(\"\") 개수 확인\n",
    "train_data.replace(\"\", np.nan, inplace=True) # 비어있는 값(\"\") 널값으로 변환\n",
    "\n",
    "train_data[train_data['document'].isnull()==True]\n",
    "print(train_data['document'].isnull().sum())\n",
    "\n",
    "# 결측치 확인\n",
    "\n",
    "print(len(test_data[test_data['document']==\"\"]), test_data['document'].isnull().sum()) # 비어있는 값(\"\") 개수 확인\n",
    "test_data.replace(\"\", np.nan, inplace=True) # 비어있는 값(\"\") 널값으로 변환\n",
    "\n",
    "test_data[test_data['document'].isnull()==True]\n",
    "print(test_data['document'].isnull().sum())\n",
    "\n",
    "# 결측치 제거\n",
    "\n",
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "# 결측치 확인\n",
    "\n",
    "print(train_data['document'].isnull().sum(), test_data['document'].isnull().sum())\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 띄어쓰기, 맞춤법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\n",
      "흠포스터 보고 초딩 영화 줄오버 연기조차 가볍지 않구나\n"
     ]
    }
   ],
   "source": [
    "spacing = Spacing()\n",
    "\n",
    "test_sentence = train_data.iloc[1, 1]\n",
    "spaced_sentence = spacing(test_sentence)\n",
    "print(test_sentence)\n",
    "print(spaced_sentence)\n",
    "\n",
    "test_sentence = train_data.iloc[2, 1]\n",
    "spaced_sentence = spacing(test_sentence)\n",
    "print(test_sentence)\n",
    "print(spaced_sentence)\n",
    "\n",
    "test_sentence = train_data.iloc[10, 1]\n",
    "spaced_sentence = spacing(test_sentence)\n",
    "print(test_sentence)\n",
    "print(spaced_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['document'] = train_data['document'].apply(spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['document'] = test_data['document'].apply(spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      9008700\n",
       "document    걍 인피니트가 짱이 다 진짜 짱이다\n",
       "label                         1\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              8425305\n",
       "document    한국독립영화의 한계 그렇게 아버지가 된다와 비교됨\n",
       "label                                 0\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_train_data = train_data.copy()\n",
    "spaced_train_data.to_csv('./data/ratings_train_spaced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_test_data = test_data.copy()\n",
    "spaced_test_data.to_csv('./data/spaced_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 띄어쓰기된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터 보고 초딩 영화 줄오버 연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무 재밓었다 그래서 보는 것을 추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다 평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬 페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어 보이기만 했던 커스...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145388</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지 소는 뭔죄인가</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145389</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145390</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐 요 한국인은 거들 먹거리고 필리핀 혼혈은 착하다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145391</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉 방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145392</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간 하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145393 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1        3819312                     흠포스터 보고 초딩 영화 줄오버 연기조차 가볍지 않구나      1\n",
       "2       10265843                             너무 재밓었다 그래서 보는 것을 추천한다      0\n",
       "3        9045019                         교도소 이야기구먼 솔직히 재미는 없다 평점 조정      0\n",
       "4        6483659  사이몬 페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어 보이기만 했던 커스...      1\n",
       "...          ...                                                ...    ...\n",
       "145388   6222902                                    인간이 문제지 소는 뭔죄인가      0\n",
       "145389   8549745                                         평점이 너무 낮아서      1\n",
       "145390   9311800                    이게 뭐 요 한국인은 거들 먹거리고 필리핀 혼혈은 착하다      0\n",
       "145391   2376369                        청춘 영화의 최고봉 방황과 우울했던 날들의 자화상      1\n",
       "145392   9619869                          한국 영화 최초로 수간 하는 내용이 담긴 영화      0\n",
       "\n",
       "[145393 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/ratings_train_spaced.csv')\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형태소 분석기 종류\n",
    "\n",
    "Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 불용어 사전 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 사전 불러오기\n",
    "stopwords = pd.read_csv(\"./data/stopwords.csv\", encoding='CP949')\n",
    "stopwords = list(stopwords['stopwords'])\n",
    "\n",
    "stopwords_2 = pd.read_table(\"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Okt 사용 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = train_data.iloc[10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKT 형태소 분석 : ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍지', '않구나']\n",
      "OKT 품사 태깅 : [('흠', 'Noun'), ('포스터', 'Noun'), ('보고', 'Noun'), ('초딩', 'Noun'), ('영화', 'Noun'), ('줄', 'Noun'), ('오버', 'Noun'), ('연기', 'Noun'), ('조차', 'Josa'), ('가볍지', 'Adjective'), ('않구나', 'Verb')]\n",
      "OKT 명사 추출 : ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "print('OKT 형태소 분석 :',okt.morphs(test_sentence))\n",
    "print('OKT 품사 태깅 :',okt.pos(test_sentence))\n",
    "print('OKT 명사 추출 :',okt.nouns(test_sentence)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145393/145393 [16:19<00:00, 148.42it/s]\n"
     ]
    }
   ],
   "source": [
    "okt_x_train = []\n",
    "\n",
    "for sentence in tqdm(train_data['document']): # 진행상황 Progress Bar를 위한 tqdm library\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    okt_x_train.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48852/48852 [06:56<00:00, 117.16it/s]\n"
     ]
    }
   ],
   "source": [
    "okt_x_test = []\n",
    "for sentence in tqdm(test_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    okt_x_test.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(okt_x_train).to_csv(\"./data/okt_x_train.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(okt_x_test).to_csv(\"./data/okt_x_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['더빙', '진짜', '짜증나다', '목소리']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['너무', '재밓었다', '보다', '추천', '하다']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['교도소', '이야기', '구먼', '솔직하다', '재미', '는', '없다', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['사이', '몬', '페그', '익살스럽다', '연기', '돋보이다', '영화',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145388</th>\n",
       "      <td>['인간', '문제', '지', '소', '는', '뭔', '죄인']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145389</th>\n",
       "      <td>['평점', '너무', '낮다']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145390</th>\n",
       "      <td>['게', '뭐', '요', '한국인', '은', '거들다', '먹거리', '고',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145391</th>\n",
       "      <td>['청춘', '영화', '최고봉', '방황', '우울하다', '날', '자화상']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145392</th>\n",
       "      <td>['한국', '영화', '최초', '수간', '하다', '내용', '담기다', '영화']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145393 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0                             ['더빙', '진짜', '짜증나다', '목소리']\n",
       "1       ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기'...\n",
       "2                        ['너무', '재밓었다', '보다', '추천', '하다']\n",
       "3       ['교도소', '이야기', '구먼', '솔직하다', '재미', '는', '없다', ...\n",
       "4       ['사이', '몬', '페그', '익살스럽다', '연기', '돋보이다', '영화',...\n",
       "...                                                   ...\n",
       "145388             ['인간', '문제', '지', '소', '는', '뭔', '죄인']\n",
       "145389                                 ['평점', '너무', '낮다']\n",
       "145390  ['게', '뭐', '요', '한국인', '은', '거들다', '먹거리', '고',...\n",
       "145391      ['청춘', '영화', '최고봉', '방황', '우울하다', '날', '자화상']\n",
       "145392  ['한국', '영화', '최초', '수간', '하다', '내용', '담기다', '영화']\n",
       "\n",
       "[145393 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_x_train = pd.read_csv('./data/okt_x_train.csv', encoding='CP949')\n",
    "okt_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['굳다', 'ㅋ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['뭐', '평점', '은', '나쁘다', '않다', '점', '짜다', '리', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['지루하다', '않다', '완전', '막장', '임', '돈', '주다', '보기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['만', '아니다', '별', '개', '주다', '나오다', '심기', '불편하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['음악', '주가', '되다', '최고', '음악', '영화']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48847</th>\n",
       "      <td>['오랜', '만', '평점', '기다', '하다', 'ㅋㅋ', '킹왕짱', '쌈뽕...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48848</th>\n",
       "      <td>['의지', '박약', '이나', '하다', '탈영', '은', '주인공', '김대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>['그림', '도', '좋다', '완성', '도도', '높다', '보다', '내내'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>['절대', '보다', '서다', '안', '되다', '영화', '재미', '도',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>['마무리', '는']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48852 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0                                            ['굳다', 'ㅋ']\n",
       "1      ['뭐', '평점', '은', '나쁘다', '않다', '점', '짜다', '리', ...\n",
       "2      ['지루하다', '않다', '완전', '막장', '임', '돈', '주다', '보기...\n",
       "3      ['만', '아니다', '별', '개', '주다', '나오다', '심기', '불편하...\n",
       "4                   ['음악', '주가', '되다', '최고', '음악', '영화']\n",
       "...                                                  ...\n",
       "48847  ['오랜', '만', '평점', '기다', '하다', 'ㅋㅋ', '킹왕짱', '쌈뽕...\n",
       "48848  ['의지', '박약', '이나', '하다', '탈영', '은', '주인공', '김대...\n",
       "48849  ['그림', '도', '좋다', '완성', '도도', '높다', '보다', '내내'...\n",
       "48850  ['절대', '보다', '서다', '안', '되다', '영화', '재미', '도',...\n",
       "48851                                       ['마무리', '는']\n",
       "\n",
       "[48852 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_x_test = pd.read_csv('./data/okt_x_test.csv')\n",
    "okt_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 꼬꼬마 Kkma 사용 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꼬꼬마 형태소 분석 : ['걍', '인피', '니트', '가', '짱', '이', '다', '진짜', '짱', '이', '다']\n",
      "꼬꼬마 품사 태깅 : [('걍', 'MAG'), ('인피', 'NNG'), ('니트', 'NNG'), ('가', 'JKS'), ('짱', 'NNG'), ('이', 'JKS'), ('다', 'MAG'), ('진짜', 'MAG'), ('짱', 'NNG'), ('이', 'VCP'), ('다', 'EFN')]\n",
      "꼬꼬마 명사 추출 : ['인피', '인피니트', '니트', '짱']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "kkma = Kkma()\n",
    "\n",
    "test_sentence = train_data.iloc[10, 1]\n",
    "\n",
    "print('꼬꼬마 형태소 분석 :',kkma.morphs(test_sentence))\n",
    "print('꼬꼬마 품사 태깅 :',kkma.pos(test_sentence))\n",
    "print('꼬꼬마 명사 추출 :',kkma.nouns(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:JVM is already running. Do not init twice!\n"
     ]
    }
   ],
   "source": [
    "init_jvm(jvmpath=None, max_heap_size='9096M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma_x_train = []\n",
    "\n",
    "for sentence in tqdm(train_data['document']): # 진행상황 Progress Bar를 위한 tqdm library\n",
    "    tokenized_sentence = kkma.morphs(sentence) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    kkma_x_train.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 은전한닢 형태소 분석기 mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://eunjeon.blogspot.com/\n",
    "\n",
    "https://cleancode-ws.tistory.com/97\n",
    "\n",
    "https://m.blog.naver.com/PostView.nhn?blogId=aul-_-&logNo=221557243190&proxyReferer=https:%2F%2Fwww.google.com%2F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 코모란 KOMORAN 사용 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 한나눔 Hannanum 사용 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Okt 데이터 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              ['굳다', 'ㅋ']\n",
       "1        ['뭐', '평점', '은', '나쁘다', '않다', '점', '짜다', '리', ...\n",
       "2        ['지루하다', '않다', '완전', '막장', '임', '돈', '주다', '보기...\n",
       "3        ['만', '아니다', '별', '개', '주다', '나오다', '심기', '불편하...\n",
       "4                     ['음악', '주가', '되다', '최고', '음악', '영화']\n",
       "                               ...                        \n",
       "48847    ['오랜', '만', '평점', '기다', '하다', 'ㅋㅋ', '킹왕짱', '쌈뽕...\n",
       "48848    ['의지', '박약', '이나', '하다', '탈영', '은', '주인공', '김대...\n",
       "48849    ['그림', '도', '좋다', '완성', '도도', '높다', '보다', '내내'...\n",
       "48850    ['절대', '보다', '서다', '안', '되다', '영화', '재미', '도',...\n",
       "48851                                         ['마무리', '는']\n",
       "Name: 0, Length: 48852, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_x_train = pd.read_csv('./data/okt_x_train.csv', encoding='CP949')\n",
    "okt_x_train = pd.Series(okt_x_train['0'])\n",
    "okt_x_train\n",
    "\n",
    "okt_x_test = pd.read_csv('./data/okt_x_test.csv')\n",
    "okt_x_test = pd.Series(okt_x_test['0'])\n",
    "okt_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 40250\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 22043\n",
      "단어 집합에서 희귀 단어의 비율: 54.76521739130435\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.6915669365701103\n",
      "단어 집합의 크기 : 18208\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(okt_x_train)\n",
    "\n",
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "# 0번 패딩 토큰을 고려하여 + 1\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(okt_x_train)\n",
    "X_train = tokenizer.texts_to_sequences(okt_x_train)\n",
    "X_test = tokenizer.texts_to_sequences(okt_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7898805</td>\n",
       "      <td>음악이 주가 된 최고의 음악영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>4608761</td>\n",
       "      <td>오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>5308387</td>\n",
       "      <td>의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9072549</td>\n",
       "      <td>그림도 좋고 완성도도 높았지만 보는 내내 불안하게 만든다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>5802125</td>\n",
       "      <td>절대 봐서는 안 될 영화 재미도 없고 기분만 잡치고 한 세트장에서 다 해먹네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>6070594</td>\n",
       "      <td>마무리는 또 왜이래</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48852 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                    document  label\n",
       "0      6270596                                         굳 ㅋ      1\n",
       "2      8544678            뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
       "3      6825595                   지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
       "4      6723715   만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0\n",
       "5      7898805                           음악이 주가 된 최고의 음악영화      1\n",
       "...        ...                                         ...    ...\n",
       "49995  4608761   오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
       "49996  5308387    의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따       0\n",
       "49997  9072549             그림도 좋고 완성도도 높았지만 보는 내내 불안하게 만든다      0\n",
       "49998  5802125  절대 봐서는 안 될 영화 재미도 없고 기분만 잡치고 한 세트장에서 다 해먹네      0\n",
       "49999  6070594                                  마무리는 또 왜이래      0\n",
       "\n",
       "[48852 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145082\n",
      "145082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huitaek\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 68\n",
      "리뷰의 평균 길이 : 10.941812216539612\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 30 이하인 샘플의 비율: 94.15778663100866\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))\n",
    "\n",
    "max_len = 30\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145082 48852 145082 48852\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(X_train)\n",
    "temp.to_csv('./data/temp_dataset/X_train.csv', index=False)\n",
    "temp = pd.DataFrame(X_test)\n",
    "temp.to_csv('./data/temp_dataset/X_test.csv', index=False)\n",
    "temp = pd.DataFrame(y_train)\n",
    "temp.to_csv('./data/temp_dataset/y_train.csv', index=False)\n",
    "temp = pd.DataFrame(y_test)\n",
    "temp.to_csv('./data/temp_dataset/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1814/1814 [==============================] - 163s 88ms/step - loss: 0.3930 - acc: 0.8201 - val_loss: 0.3624 - val_acc: 0.8399\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83989, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "1814/1814 [==============================] - 159s 88ms/step - loss: 0.3324 - acc: 0.8552 - val_loss: 0.3368 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83989 to 0.85250, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "1814/1814 [==============================] - 161s 89ms/step - loss: 0.3074 - acc: 0.8687 - val_loss: 0.3375 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.85250\n",
      "Epoch 4/15\n",
      "1814/1814 [==============================] - 155s 85ms/step - loss: 0.2885 - acc: 0.8788 - val_loss: 0.3316 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85250 to 0.85384, saving model to best_model.h5\n",
      "Epoch 5/15\n",
      "1814/1814 [==============================] - 158s 87ms/step - loss: 0.2724 - acc: 0.8877 - val_loss: 0.3342 - val_acc: 0.8555\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85384 to 0.85550, saving model to best_model.h5\n",
      "Epoch 6/15\n",
      "1814/1814 [==============================] - 157s 87ms/step - loss: 0.2583 - acc: 0.8945 - val_loss: 0.3428 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.85550\n",
      "Epoch 7/15\n",
      "1814/1814 [==============================] - 158s 87ms/step - loss: 0.2435 - acc: 0.9020 - val_loss: 0.3406 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.85550\n",
      "Epoch 8/15\n",
      "1814/1814 [==============================] - 155s 86ms/step - loss: 0.2286 - acc: 0.9089 - val_loss: 0.3453 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.85550\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 25s 16ms/step - loss: 0.3458 - acc: 0.8518\n",
      "\n",
      " 테스트 정확도: 0.8518\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "099c82bb4ace82ade8ea00d06692c6005c84f3239a96c9207fc6992d929102eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
