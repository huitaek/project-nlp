{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리한 데이터셋 불러오기\n",
    "\n",
    "X_train = np.array(pd.read_csv('./data/okt/X_train.csv'))\n",
    "X_test = np.array(pd.read_csv('./data/okt/X_test.csv'))\n",
    "y_train = np.array(pd.read_csv('./data/okt/y_train.csv'))\n",
    "y_test = np.array(pd.read_csv('./data/okt/y_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Sigmoid / hidden=128, / emb_dim=100 / epochs=15 / batch=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1949/1949 [==============================] - 201s 103ms/step - loss: 0.3875 - acc: 0.8251 - val_loss: 0.3559 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83692, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "1949/1949 [==============================] - 223s 115ms/step - loss: 0.3254 - acc: 0.8590 - val_loss: 0.3319 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83692 to 0.84968, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "1949/1949 [==============================] - 229s 117ms/step - loss: 0.2999 - acc: 0.8722 - val_loss: 0.3269 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84968 to 0.85693, saving model to best_model.h5\n",
      "Epoch 4/15\n",
      "1949/1949 [==============================] - 225s 115ms/step - loss: 0.2814 - acc: 0.8823 - val_loss: 0.3245 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85693 to 0.86001, saving model to best_model.h5\n",
      "Epoch 5/15\n",
      "1949/1949 [==============================] - 218s 112ms/step - loss: 0.2653 - acc: 0.8919 - val_loss: 0.3382 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.86001\n",
      "Epoch 6/15\n",
      "1949/1949 [==============================] - 228s 117ms/step - loss: 0.2511 - acc: 0.8986 - val_loss: 0.3400 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.86001\n",
      "Epoch 7/15\n",
      "1949/1949 [==============================] - 214s 110ms/step - loss: 0.2367 - acc: 0.9051 - val_loss: 0.3502 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.86001\n",
      "Epoch 8/15\n",
      "1949/1949 [==============================] - 217s 112ms/step - loss: 0.2227 - acc: 0.9118 - val_loss: 0.3473 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.86001\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "vocab_size = 19395\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 31s 20ms/step - loss: 0.3366 - acc: 0.8563\n",
      "\n",
      " 테스트 정확도: 0.8563\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1949/1949 [==============================] - 245s 125ms/step - loss: 0.4953 - acc: 0.7992 - val_loss: 0.6782 - val_acc: 0.8190\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.81895, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "1949/1949 [==============================] - 219s 112ms/step - loss: 0.4182 - acc: 0.8453 - val_loss: 0.5423 - val_acc: 0.8402\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.81895 to 0.84022, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "1949/1949 [==============================] - 228s 117ms/step - loss: 0.4355 - acc: 0.8570 - val_loss: 0.5182 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84022 to 0.84359, saving model to best_model.h5\n",
      "Epoch 4/15\n",
      "1949/1949 [==============================] - 234s 120ms/step - loss: 0.4253 - acc: 0.8641 - val_loss: 0.4731 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84359 to 0.84574, saving model to best_model.h5\n",
      "Epoch 5/15\n",
      "1949/1949 [==============================] - 231s 118ms/step - loss: 0.4478 - acc: 0.8651 - val_loss: 0.4200 - val_acc: 0.8376\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.84574\n",
      "Epoch 6/15\n",
      "1949/1949 [==============================] - 234s 120ms/step - loss: 0.4699 - acc: 0.8636 - val_loss: 0.7585 - val_acc: 0.8352\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.84574\n",
      "Epoch 7/15\n",
      "1949/1949 [==============================] - 238s 122ms/step - loss: 0.4996 - acc: 0.8638 - val_loss: 0.6440 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.84574\n",
      "Epoch 8/15\n",
      "1939/1949 [============================>.] - ETA: 1s - loss: 0.5167 - acc: 0.8592"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-eab9a4078f6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 _r=1):\n\u001b[0;32m   1177\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "vocab_size = 19395\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='softsign'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 7s 4ms/step - loss: 0.4158 - acc: 0.8475\n",
      "\n",
      " 테스트 정확도: 0.8475\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1816/1816 [==============================] - 98s 53ms/step - loss: 0.3985 - acc: 0.8201 - val_loss: 0.3525 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.84344, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "1816/1816 [==============================] - 91s 50ms/step - loss: 0.3333 - acc: 0.8562 - val_loss: 0.3410 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.84344 to 0.84929, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "1816/1816 [==============================] - 93s 51ms/step - loss: 0.3096 - acc: 0.8693 - val_loss: 0.3247 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84929 to 0.85849, saving model to best_model.h5\n",
      "Epoch 4/15\n",
      "1816/1816 [==============================] - 98s 54ms/step - loss: 0.2909 - acc: 0.8797 - val_loss: 0.3286 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.85849\n",
      "Epoch 5/15\n",
      "1816/1816 [==============================] - 104s 57ms/step - loss: 0.2768 - acc: 0.8870 - val_loss: 0.3213 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85849 to 0.85997, saving model to best_model.h5\n",
      "Epoch 6/15\n",
      "1816/1816 [==============================] - 105s 58ms/step - loss: 0.2645 - acc: 0.8931 - val_loss: 0.3289 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85997 to 0.86045, saving model to best_model.h5\n",
      "Epoch 7/15\n",
      "1816/1816 [==============================] - 106s 58ms/step - loss: 0.2528 - acc: 0.8979 - val_loss: 0.3635 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.86045\n",
      "Epoch 8/15\n",
      "1816/1816 [==============================] - 105s 58ms/step - loss: 0.2411 - acc: 0.9035 - val_loss: 0.3376 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.86045\n",
      "Epoch 9/15\n",
      "1816/1816 [==============================] - 103s 57ms/step - loss: 0.2295 - acc: 0.9096 - val_loss: 0.3419 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.86045\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "vocab_size = 18437\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 12s 8ms/step - loss: 0.3358 - acc: 0.8574\n",
      "\n",
      " 테스트 정확도: 0.8574\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          ['아', '더빙', '진짜', '짜증나다', '목소리']\n",
       "1         ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기'...\n",
       "2         ['너무', '재밓었다', '그래서', '보다', '것', '을', '추천', '하다']\n",
       "3         ['교도소', '이야기', '구먼', '솔직하다', '재미', '는', '없다', ...\n",
       "4         ['사이', '몬', '페그', '의', '익살스럽다', '연기', '가', '돋보...\n",
       "                                ...                        \n",
       "145388     ['인간', '이', '문제', '지', '소', '는', '뭔', '죄인', '가']\n",
       "145389                              ['평점', '이', '너무', '낮다']\n",
       "145390    ['이', '게', '뭐', '요', '한국인', '은', '거들다', '먹거리',...\n",
       "145391    ['청춘', '영화', '의', '최고봉', '방황', '과', '우울하다', '날...\n",
       "145392    ['한국', '영화', '최초', '로', '수간', '하다', '내용', '이',...\n",
       "Name: 0, Length: 145393, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "okt_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"['재밌다']\", 110),\n",
       " (\"['좋다']\", 80),\n",
       " (\"['재미있다']\", 70),\n",
       " (\"['재미없다']\", 60),\n",
       " (\"['말', '이', '필요', '없다']\", 34),\n",
       " (\"['괜찮다']\", 30),\n",
       " (\"['굿']\", 29),\n",
       " (\"['잼', '있다']\", 29),\n",
       " (\"['재밌다', '보다']\", 29),\n",
       " (\"['정말', '재미있다']\", 28),\n",
       " (\"['최고']\", 27),\n",
       " (\"['지루하다']\", 26),\n",
       " (\"['점']\", 24),\n",
       " (\"['너무', '재밌다']\", 24),\n",
       " (\"['짱']\", 24),\n",
       " (\"['정말', '재밌다']\", 24),\n",
       " (\"['별로']\", 23),\n",
       " (\"['너무', '재미있다']\", 21),\n",
       " (\"['자다', '보다']\", 20),\n",
       " (\"['멋지다']\", 18),\n",
       " (\"['쓰레기']\", 17),\n",
       " (\"['재미있다', '자다', '보다']\", 17),\n",
       " (\"['너무', '좋다']\", 17),\n",
       " (\"['하다', '말', '이', '없다']\", 16),\n",
       " (\"['정말', '재미없다']\", 16),\n",
       " (\"['재미있다', '보다']\", 16),\n",
       " (\"['재밌다', '데']\", 15),\n",
       " (\"['하다', '말', '없다']\", 15),\n",
       " (\"['음']\", 15),\n",
       " (\"['이건', '아니다']\", 15),\n",
       " (\"['내', '인생', '최고', '의', '영화']\", 14),\n",
       " (\"['진짜', '재미없다']\", 14),\n",
       " (\"['좋다', '좋다']\", 14),\n",
       " (\"['점도', '아깝다']\", 14),\n",
       " (\"['그저', '그렇다']\", 14),\n",
       " (\"['재미', '가', '없다']\", 14),\n",
       " (\"['완전', '재밌다']\", 14),\n",
       " (\"['좋다', '영화']\", 13),\n",
       " (\"['최고', '이다']\", 13),\n",
       " (\"['왜', '만들다']\", 13),\n",
       " (\"['감동', '적', '이다']\", 13),\n",
       " (\"['또', '보고', '싶다']\", 12),\n",
       " (\"['진짜', '재밌다']\", 12),\n",
       " (\"['점', '만점', '에', '점']\", 12),\n",
       " (\"['유치하다']\", 12),\n",
       " (\"['대박']\", 11),\n",
       " (\"['아']\", 11),\n",
       " (\"['자', '제한']\", 11),\n",
       " (\"['이건', '뭐']\", 11),\n",
       " (\"['짱', '재밌다']\", 11),\n",
       " (\"['감동']\", 11),\n",
       " (\"['보다', '자다']\", 11),\n",
       " (\"['최악', '이다']\", 11),\n",
       " (\"['최고', '의', '드라마']\", 10),\n",
       " (\"['재밌다', 'ㅎㅎ']\", 10),\n",
       " (\"['에', '휴']\", 10),\n",
       " (\"['볼', '만', '하다']\", 10),\n",
       " (\"['재미', '없다']\", 10),\n",
       " (\"['잼', '없다']\", 10),\n",
       " (\"['최악']\", 10),\n",
       " (\"['진짜', '재미있다']\", 10),\n",
       " (\"['꼭', '보다']\", 10),\n",
       " (\"['재다']\", 10),\n",
       " (\"['너무', '지루하다']\", 10),\n",
       " (\"['재밌다', '자다', '보다']\", 10),\n",
       " (\"['최고', '의', '영화']\", 9),\n",
       " (\"['글쎄']\", 9),\n",
       " (\"['시간', '아깝다']\", 9),\n",
       " (\"['평점', '이', '너무', '낮다']\", 9),\n",
       " (\"['넘다', '재밌다']\", 9),\n",
       " (\"['훈훈하다']\", 9),\n",
       " (\"['짜증나다']\", 9),\n",
       " (\"['아름답다']\", 9),\n",
       " (\"['정말', '좋다']\", 9),\n",
       " (\"['점', '은', '되다']\", 9),\n",
       " (\"['정말', '재밌다', '보다']\", 9),\n",
       " (\"['재밌다', 'ㅋㅋ']\", 9),\n",
       " (\"['그냥', '그렇다']\", 9),\n",
       " (\"['다시', '보고', '싶다']\", 9),\n",
       " (\"['점', '은', '없다']\", 8),\n",
       " (\"['이건', '좀', '아니다']\", 8),\n",
       " (\"['전', '기세', '가', '아깝다']\", 8),\n",
       " (\"['별루']\", 8),\n",
       " (\"['아름답다', '영화']\", 8),\n",
       " (\"['최고다']\", 8),\n",
       " (\"['보고', '싶다']\", 8),\n",
       " (\"['돈', '아깝다']\", 8),\n",
       " (\"['내', '인생', '최고', '의', '드라마']\", 8),\n",
       " (\"['재밋다']\", 8),\n",
       " (\"['하']\", 8),\n",
       " (\"['최악', '의', '영화']\", 8),\n",
       " (\"['좋다', '영화', '이다']\", 8),\n",
       " (\"['완전', '재미있다']\", 8),\n",
       " (\"['재미', '잇다']\", 8),\n",
       " (\"['훌륭하다']\", 8),\n",
       " (\"['무슨', '말', '이', '필요하다']\", 8),\n",
       " (\"['헐다']\", 8),\n",
       " (\"['재미있다', 'ㅋㅋ']\", 8),\n",
       " (\"['장난', '하다']\", 8),\n",
       " (\"['슬프다']\", 8)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "\n",
    "    vocab = FreqDist(np.hstack(okt_x_train))\n",
    "temp = vocab.most_common(100)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 빈도 수 확인\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "vocab = FreqDist(np.hstack(okt_x_train))\n",
    "temp = vocab.most_common(100)\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for i in tqdm(range(0, 100)):\n",
    "    \n",
    "    temp_list.append(str(temp[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['재밌다']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(temp_list)\n",
    "temp_list[0].lstrip('\\\"')\n",
    "\n",
    "output=eval(temp_list[0].lstrip('\\\"'))\n",
    "output=eval(temp_list[0].rstrip('\\''))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "phrase input should be string, not <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;32m<ipython-input-202-df31c3dbad1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[0mOkt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOkt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m----> 2\u001b[1;33m \u001b[0mOkt_morphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOkt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_list\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 튜플반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOkt_morphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[0mNoun_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n",
      "\u001b[0;32m     67\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mjoined\u001b[0m \u001b[0msets\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmorph\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     68\u001b[0m         \"\"\"\n",
      "\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mvalidate_phrase_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     71\u001b[0m         tokens = self.jki.tokenize(\n",
      "\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_common.py\u001b[0m in \u001b[0;36mvalidate_phrase_inputs\u001b[1;34m(phrase)\u001b[0m\n",
      "\u001b[0;32m     18\u001b[0m     \"\"\"\n",
      "\u001b[0;32m     19\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"phrase input should be string, not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: phrase input should be string, not <class 'list'>"
     ]
    }
   ],
   "source": [
    "Okt = konlpy.tag.Okt()\n",
    "Okt_morphs = Okt.pos(temp_list)  # 튜플반환\n",
    "print(Okt_morphs)\n",
    "\n",
    "Noun_words = []\n",
    "for word, pos in Okt_morphs:\n",
    "    if pos == 'Noun':\n",
    "        Noun_words.append(word)\n",
    "print(Noun_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(Noun_words)\n",
    "print(c.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "\n",
    "FONT_PATH = 'C:/Windows/Fonts/malgun.ttf' # For Korean characters\n",
    "\n",
    "noun_text = ''\n",
    "for word in Noun_words:\n",
    "    noun_text = noun_text +' '+word\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=60, relative_scaling=.5, font_path=FONT_PATH).generate(noun_text) # generate() 는 하나의 string value를 입력 받음\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "099c82bb4ace82ade8ea00d06692c6005c84f3239a96c9207fc6992d929102eb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
