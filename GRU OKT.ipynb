{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f5421f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'java'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!java -version\n",
    "# C:\\Program Files\\Java\\jre1.8.0_321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a120728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)   # validation의 정확도 최대일때 저장\n",
    "es = EarlyStopping(monitor='val_accuracy',mode='max',patience=5)\n",
    "# tvalidation의 정확도 최대일때. patience는 기준되는 값이 연속으로 몇 번 이상 향상되지 않을 때 종료시킬 것인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73192bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>528</td>\n",
       "      <td>32</td>\n",
       "      <td>408</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>507</td>\n",
       "      <td>45</td>\n",
       "      <td>674</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>1360</td>\n",
       "      <td>36</td>\n",
       "      <td>1003</td>\n",
       "      <td>720</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>577</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6396</td>\n",
       "      <td>125</td>\n",
       "      <td>5999</td>\n",
       "      <td>253</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "      <td>3566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1122</td>\n",
       "      <td>257</td>\n",
       "      <td>3</td>\n",
       "      <td>10090</td>\n",
       "      <td>11825</td>\n",
       "      <td>7</td>\n",
       "      <td>1116</td>\n",
       "      <td>1</td>\n",
       "      <td>1404</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155863</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1087</td>\n",
       "      <td>4173</td>\n",
       "      <td>5</td>\n",
       "      <td>7939</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>182</td>\n",
       "      <td>39</td>\n",
       "      <td>444</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>266</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>6</td>\n",
       "      <td>819</td>\n",
       "      <td>1907</td>\n",
       "      <td>659</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>692</td>\n",
       "      <td>4854</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>191</td>\n",
       "      <td>105</td>\n",
       "      <td>191</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>61</td>\n",
       "      <td>1116</td>\n",
       "      <td>865</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155866</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>285</td>\n",
       "      <td>1116</td>\n",
       "      <td>1610</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>1461</td>\n",
       "      <td>1116</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4729</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>2687</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155868 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2  3  4     5     6  7     8  9  ...    35    36    37     38  \\\n",
       "0       0  0  0  0  0     0     0  0     0  0  ...     0     0     0      0   \n",
       "1       0  0  0  0  0     0     0  0     0  0  ...   507    45   674      2   \n",
       "2       0  0  0  0  0     0     0  0     0  0  ...     0     0     0     19   \n",
       "3       0  0  0  0  0     0     0  0     0  0  ...     0  6396   125   5999   \n",
       "4       0  0  0  0  0     0     0  0     0  0  ...  1122   257     3  10090   \n",
       "...    .. .. .. .. ..   ...   ... ..   ... ..  ...   ...   ...   ...    ...   \n",
       "155863  0  0  0  0  0  1087  4173  5  7939  8  ...    15    40    73    182   \n",
       "155864  0  0  0  0  0     0     0  0     0  0  ...   146     6   819   1907   \n",
       "155865  0  0  0  0  0     0     0  0     0  0  ...   105   191   105    191   \n",
       "155866  0  0  0  0  0     0     0  0     0  0  ...     5   285  1116   1610   \n",
       "155867  0  0  0  0  0     0     0  0     0  0  ...     1    31  4729    439   \n",
       "\n",
       "           39    40    41    42    43    44  \n",
       "0           0    72   528    32   408   699  \n",
       "1         101  1360    36  1003   720    35  \n",
       "2         577     4    21     8   234     3  \n",
       "3         253    70    12    14    49  3566  \n",
       "4       11825     7  1116     1  1404   257  \n",
       "...       ...   ...   ...   ...   ...   ...  \n",
       "155863     39   444    66    10   266   596  \n",
       "155864    659    15     3   692  4854    35  \n",
       "155865     95    45    61  1116   865   636  \n",
       "155866     41     5  1461  1116    93     3  \n",
       "155867      5  2687    15    95   154     4  \n",
       "\n",
       "[155868 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/git_project/natural/data/okt/X_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d4350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = pd.read_csv('C:/git_project/natural/data/okt/X_train.csv')   # 데이터 불러오기\n",
    "X_test_data = pd.read_csv('C:/git_project/natural/data/okt/X_test.csv')\n",
    "y_train_data = pd.read_csv('C:/git_project/natural/data/okt/y_train.csv')   # 데이터 불러오기\n",
    "y_test_data = pd.read_csv('C:/git_project/natural/data/okt/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc26c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data.dropna(how='any', inplace=True)    # null값 탈락\n",
    "X_test_data.dropna(how='any', inplace=True)\n",
    "y_train_data.dropna(how='any', inplace=True)\n",
    "y_test_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965a4909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,    0, ...,   32,  408,  699],\n",
       "        [   0,    0,    0, ..., 1003,  720,   35],\n",
       "        [   0,    0,    0, ...,    8,  234,    3],\n",
       "        ...,\n",
       "        [   0,    0,    0, ..., 1116,  865,  636],\n",
       "        [   0,    0,    0, ..., 1116,   93,    3],\n",
       "        [   0,    0,    0, ...,   95,  154,    4]], dtype=int64),\n",
       " array([[   0,    0,    0, ...,    0,  815,  119],\n",
       "        [   0,    0,    0, ...,   64,  745,   34],\n",
       "        [   0,    0,    0, ...,   86,  170,  295],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,  180, 3045,   40],\n",
       "        [   0,    0,    0, ...,   11,  255,  151],\n",
       "        [   0,    0,    0, ...,  143,   59,   46]], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array(X_train_data)    # array로 변경하여 tensor\n",
    "test_X = np.array(X_test_data)\n",
    "train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29dcac48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=int64),\n",
       " array([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np.array(y_train_data)\n",
    "test_y = np.array(y_test_data)\n",
    "train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9ffcf",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2664f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          620640    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 32)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              37632     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                2064      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 660,353\n",
      "Trainable params: 660,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 19395                                                   #전처리 이후 사이즈 확인\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 32, mask_zero=True))   # 임베딩 32\n",
    "model.add(keras.layers.Dropout(0.5))                                 # dropout 0.2 - 0.5사이\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(64)))          # 노드  64\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(16, activation='softsign'))            # softsign, tanh로 돌려봄\n",
    "model.add(keras.layers.Dropout(0.5))  \n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a87716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd89561",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be573f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_data, y_train_data))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test_data, y_test_data))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024, reshuffle_each_iteration=True).batch(128)  # batch_size 64,128,256 확인\n",
    "val_dataset = val_dataset.batch(1000)\n",
    "\n",
    "train_dataset = train_dataset.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a0efb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1218/1218 [==============================] - 80s 61ms/step - loss: 0.4218 - accuracy: 0.8080 - val_loss: 0.5001 - val_accuracy: 0.7488\n",
      "Epoch 2/10\n",
      "1218/1218 [==============================] - 76s 62ms/step - loss: 0.3565 - accuracy: 0.8517 - val_loss: 0.4320 - val_accuracy: 0.7949\n",
      "Epoch 3/10\n",
      "1218/1218 [==============================] - 78s 64ms/step - loss: 0.3388 - accuracy: 0.8620 - val_loss: 0.3942 - val_accuracy: 0.8234\n",
      "Epoch 4/10\n",
      "1218/1218 [==============================] - 75s 61ms/step - loss: 0.3217 - accuracy: 0.8702 - val_loss: 0.3829 - val_accuracy: 0.8260\n",
      "Epoch 5/10\n",
      "1218/1218 [==============================] - 110s 91ms/step - loss: 0.3093 - accuracy: 0.8767 - val_loss: 0.3809 - val_accuracy: 0.8265\n",
      "Epoch 6/10\n",
      "1218/1218 [==============================] - 122s 100ms/step - loss: 0.2974 - accuracy: 0.8817 - val_loss: 0.3640 - val_accuracy: 0.8356\n",
      "Epoch 7/10\n",
      "1218/1218 [==============================] - 115s 94ms/step - loss: 0.2854 - accuracy: 0.8877 - val_loss: 0.3839 - val_accuracy: 0.8317\n",
      "Epoch 8/10\n",
      "1218/1218 [==============================] - 110s 90ms/step - loss: 0.2757 - accuracy: 0.8921 - val_loss: 0.3650 - val_accuracy: 0.8370\n",
      "Epoch 9/10\n",
      "1218/1218 [==============================] - 105s 87ms/step - loss: 0.2686 - accuracy: 0.8958 - val_loss: 0.3586 - val_accuracy: 0.8420\n",
      "Epoch 10/10\n",
      "1218/1218 [==============================] - 120s 99ms/step - loss: 0.2597 - accuracy: 0.8989 - val_loss: 0.3589 - val_accuracy: 0.8474\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, verbose=1,callbacks=[mc]) \n",
    "#callbacks로 체크포인트 확인 epochs 10,20회 반복으로 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9781edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('GRU_okt_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8fe39fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 11s 6ms/step - loss: 0.3589 - accuracy: 0.8474\n",
      "\n",
      " 테스트 정확도: 0.8474\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('GRU_okt_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test_data, y_test_data)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725a33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "840e47b3",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 조절\n",
    "#### OKT, tanh 사용 epochs 10회씩\n",
    "drop out ---> 0.2 \n",
    "batch size --->   256 =>128\n",
    "layer ---->  32 , 중간 GRU(64)는 건들지 않음,  16\n",
    "\n",
    "\n",
    "drop out --->    0.4\n",
    "batch size ---> 128\n",
    "layer ---->  32  , 중간 GRU(64)는 건들지 않음,  16\n",
    "\n",
    "\n",
    "drop out --->  0.4 \n",
    "batch size --->  128\n",
    "layer ---->  32 =>16 , 중간 GRU(64)는 건들지 않음,  16=>8\n",
    "\n",
    "\n",
    "drop out --->   0.5\n",
    "batch size --->   128\n",
    "layer ---->  16 , 중간 GRU(64)는 건들지 않음,  8\n",
    "\n",
    "\n",
    "drop out --->   0.5\n",
    "batch size --->   128\n",
    "layer ---->  8 , 중간 GRU(64)는 건들지 않음,  4\n",
    "\n",
    "\n",
    "drop out --->   0.5\n",
    "batch size --->   64\n",
    "layer ---->  8 , 중간 GRU(64)는 건들지 않음,  4\n",
    "\n",
    "\n",
    "drop out --->   0.5\n",
    "batch size --->   128\n",
    "layer ---->  32 , 중간 GRU(64)는 건들지 않음,  16    =======> 최종 하이퍼파라미터\n",
    "\n",
    "### 이후 \n",
    "최종 하이퍼 파라미터 사용\n",
    "\n",
    "OKT\n",
    "\n",
    "softsign과 tanh 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c9a59",
   "metadata": {},
   "source": [
    "### 최고 수치\n",
    "# tanh         val_accuracy:0.8450,  val_loss:0.3586\n",
    "# softsign   val_accuracy: 0.8474,  val_loss:0.3589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4b493d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Sequential' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15180/3528024597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# prepro_configs = json.load(open(DATA_PATH+DATA_CONFIGS,'r'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mword_vocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vocab'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_vocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Sequential' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "from konlpy.tag import Okt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "okt = Okt()\n",
    "tokenizer  = Tokenizer()\n",
    "loaded_model = model\n",
    "max_len = 42\n",
    "\n",
    "# DATA_CONFIGS = 'data_configs.json'\n",
    "# prepro_configs = json.load(open(DATA_PATH+DATA_CONFIGS,'r'))\n",
    "word_vocab = tokenizer.word_index\n",
    "model['vocab'] = word_vocab\n",
    "tokenizer.fit_on_texts(word_vocab)\n",
    "\n",
    "global corpus\n",
    "global avg_emo\n",
    "global score\n",
    "\n",
    "corpus = []\n",
    "avg_emo = 0\n",
    "\n",
    "\n",
    "heal = ['여수 밤바다', '파주 평화누리공원', '순천 갈대밭', '제주도 영실코스', \n",
    "         '진주 진양호', '장흥유원지', '대구 앞산정만대', '춘천 해피초원농장' ,' 속초 해수욕장', \n",
    "         '경주 불국사', '포항 호미곶', '남해 두모마을', '대관령 하늘목장', '군산 철길마을', \n",
    "         '국립 광릉수목원', '금선사 템플스테이', '보성 제암산자연휴양림','군산 선유도']\n",
    " \n",
    "extreme= ['통영 어드벤처 타워', '제주도  스쿠버다이빙', '단양 패러글라이딩', \n",
    "          '강원 내린천 래프팅', '충주 스카이다이빙', '하남 스포츠몬스터', '서울 한강 워터 제트팩', \n",
    "          '일산 인공 서핑', '영월 동강래프팅', '여수 스카이플라이', '문경 패러글라이딩', \n",
    "          '경남 하동 하동알프스레포츠', '인천 스카이 짚라인', '강화 루지']\n",
    " \n",
    "movie=['루카','콰이어트 플레이스','크루엘라','컨저링 3:악마가 시켰다','여고괴담 여섯번째 이야기','분노의 질주: 더 얼티메이트','캐시트럭',\n",
    "'클라이밍',\n",
    "'그 여름, 가장 차가웠던',\n",
    "'폭력의 그림자',\n",
    "'청춘 선거',\n",
    "'그레타 툰베리',\n",
    "'낫아웃',\n",
    "'마세티 킬즈',\n",
    "'프로페서 앤 매드맨',\n",
    "'화이트 온 화이트',\n",
    "'아야와 마녀',\n",
    "'까치발',\n",
    "'플래시백',\n",
    "'애플',\n",
    "'혼자 사는 사람들',\n",
    "'강호아녀',\n",
    "'파이프라인',\n",
    "'분노의 질주']\n",
    " \n",
    "#음악 (네이버 바이브 참고 1위~20위)\n",
    " \n",
    "k_balad=['Timeless-SG워너비',\n",
    "'추적이는 여름 비가 되어-장범준',\n",
    "'밤하늘의 별을 (2020)-경서',\n",
    "'어떻게 이별까지 사랑하겠어, 널 사랑하는 거지-AKMU (악동뮤지션)',\n",
    "'내 입술 따뜻한 커피처럼-청하 Colde(콜드)',\n",
    "'서울의 잠 못 이루는 밤 (Feat. 이수현)-10CM',\n",
    "'잠이 오질 않네요-장범준',\n",
    "'I Love U-성시경',\n",
    "'내사람 (Partner For Life)-SG워너비',\n",
    "'취기를 빌려-산들',\n",
    "'안녕 (Hello)-조이',\n",
    "'밤편지-아이유(IU)',\n",
    "'Anti-Romantic-투모로우바이투게더',\n",
    "'너의 모든 순간-성시경',\n",
    "'좋을텐데 (If Only) (Feat. 폴킴)-조이',\n",
    "'봄 안녕 봄-아이유(IU)',\n",
    "'Love poem -아이유(IU)',\n",
    "'아이와 나의 바다-아이유(IU)',\n",
    "'벌써 일년-반하나& MJ(써니사이드)',\n",
    "'이렇게 좋아해 본 적이 없어요 -CHEEZE (치즈)'\n",
    "]\n",
    " \n",
    "k_dance=[\n",
    "'Butter-방탄소년단',\n",
    "'Next Level-aespa',\n",
    "'Dun Dun Dance-오마이걸(OH MY GIRL)',\n",
    "'치맛바람 (Chi Mat Ba Ram)-브레이브걸스(Brave Girls)',\n",
    "'Alcohol-Free-TWICE(트와이스)',\n",
    "\"롤린 (Rollin')-브레이브걸스(Brave Girls)\",\n",
    "'라일락-아이유(IU)',\n",
    "'ASAP-STAYC(스테이씨)',\n",
    "'Dynamite-방탄소년단',\n",
    "'상상더하기-MSG워너비',\n",
    "'Celebrity-아이유(IU)',\n",
    "'상상더하기-라붐(LABOUM)',\n",
    "'Ready to love-세븐틴',\n",
    "'Dolphin-오마이걸(OH MY GIRL)',\n",
    "'Lovesick Girls-BLACKPINK',\n",
    "'Pool Party (Feat. 이찬 of DKB)-브레이브걸스(Brave Girls)',\n",
    "\"Heaven's Cloud-세븐틴\",\n",
    "'체념-정상동기(김정수, 정기석, 이동휘, 이상이)',\n",
    "'어푸 (Ah puh)-아이유(IU)',\n",
    "]\n",
    " \n",
    "k_hip=[\n",
    "'마.피.아. In the morning-ITZY(있지)',\n",
    "'봄날-방탄소년단',\n",
    "'Life Goes On-방탄소년단',\n",
    "'맛 (Hot Sauce)-NCT DREAM',\n",
    "'밸런스 게임-투모로우바이투게더',\n",
    "'GAM3 BO1-세븐틴',\n",
    "'비도 오고 그래서 (Feat. 신용재)-헤이즈 (Heize)',\n",
    "'METEOR-창모(CHANGMO)',\n",
    "'DNA-방탄소년단',\n",
    "'IDOL-방탄소년단',\n",
    "'FAKE LOVE-방탄소년단',\n",
    "'피 땀 눈물-방탄소년단',\n",
    "'사이렌-호미들',\n",
    "'멜로디-ASH ISLAND',\n",
    "'I NEED U-방탄소년단',\n",
    "'아무노래-지코 (ZICO)',\n",
    "'어떻게 지내 (Prod. By VAN.C)-오반(OVAN)',\n",
    "'Rainy day (Feat. ASH ISLAND, Skinny Brown)-PATEKO(파테코)',\n",
    "'뚜두뚜두 (DDU-DU DDU-DU)-BLACKPINK']\n",
    " \n",
    " \n",
    "trt=[\n",
    "'이제 나만 믿어요-임영웅',\n",
    "'별빛 같은 나의 사랑아-임영웅',\n",
    "'다시 사랑한다면 (김필 Ver.)-임영웅',\n",
    "'HERO-임영웅',\n",
    "'미워요-임영웅',\n",
    "'잊어야 한다는 마음으로-임영웅',\n",
    "'계단말고 엘리베이터-임영웅',\n",
    "'소나기-임영웅',\n",
    "'바보같지만-임영웅',\n",
    "'따라따라-임영웅',\n",
    "'당신-임영웅',\n",
    "'내 마음 별과 같이-임영웅',\n",
    "'고맙소-김호중',\n",
    "'만개 (Prod. 신지후)-김호중',\n",
    "'나보다 더 사랑해요-김호중',\n",
    "'애인이 되어줄게요 (Prod. 알고보니, 혼수상태)-김호중',\n",
    "'퇴근길-김호중',\n",
    "'할무니-김호중',\n",
    "'우산이 없어요-김호중',\n",
    "'천년의 사랑-김호중'\n",
    "]\n",
    " \n",
    " \n",
    "f_dance=[\n",
    "'You-Regard, Troye Sivan, Tate McRae',\n",
    "'Closer (Feat. Halsey)-The Chainsmokers',\n",
    "'Faded-Alan Walker',\n",
    "'One Kiss-Calvin Harris, Dua Lipa',\n",
    "'Heartbreak Anthem-Galantis, David Guetta, Little Mix',\n",
    "'Something Just Like This-The Chainsmokers, Coldplay',\n",
    "'This Is What You Came For (Feat. Rihanna)-Calvin Harris',\n",
    "'The Middle-Zedd, Grey, Maren Morris',\n",
    "'Symphony (Feat. Zara Larsson)-Clean Bandit',\n",
    "'Wake Me Up-Avicii',\n",
    "'Waste It On Me (Feat. BTS(방탄소년단))-Steve Aoki',\n",
    "'How To Love (Feat. Sofia Reyes)-Cash Cash',\n",
    "'Bad Boy (with Wiz Khalifa, bbno$, MAX)-Yung Bae, Wiz Khalifa, bbno$, MAX',\n",
    "'Titans (Feat. Sia & Labrinth) (Imanbek Remix)-Major Lazer',\n",
    "'Feels (Feat. Pharrell Williams, Katy Perry, Big Sean)-Calvin Harris',\n",
    "'Rise (Feat. Jack & Jack)-Jonas Blue',\n",
    "'Mama (Feat. William Singe)-Jonas Blue',\n",
    "'Just Got Paid (Feat. French Montana)-Sigala, Ella Eyre, Meghan Trainor',\n",
    "'Love Line-Shift K3y, Tinashe',\n",
    "'Lonely Together (Feat. Rita Ora)-Avicii'\n",
    "]\n",
    " \n",
    "newage=[\n",
    "'River Flows In You-이루마',\n",
    "'Letter From The Earth (지구에서 온 편지)-김광민',\n",
    "'익숙한 그 집 앞-유희열',\n",
    "'처음부터 지금까지 (Inst.)-박정원',\n",
    "'냉정과 열정 사이 OST (冷靜と情熱のあいだ)-Ryo Yoshimata',\n",
    "'''Tomorrow's Promise-Kevin Kern''',\n",
    "\"Mia & Sebastian's Theme-Justin Hurwitz\",\n",
    "'Recuerods de la Alhambra (알함브라 궁전의 추억)-Claude Ciari',\n",
    "'''Gabriel's Oboe-Ennio Morricone''',\n",
    "'Rain-Ryuichi Sakamoto',\n",
    "'Romance-Yuhki Kuramoto',\n",
    "'Second Romance-Yuhki Kuramoto',\n",
    "'Crystal Rainbow-데이드림(Daydream)',\n",
    "'My Road (Live)-Lee Oskar',\n",
    "'Last Carnival-Acoustic Cafe',\n",
    "'Return To The Heart-David Lanz',\n",
    "'Adagio-Secret Garden',\n",
    "'Loving You-Kenny G'\n",
    "]\n",
    "\n",
    "korean = [\"삼계탕\", \"삼겹살\", \"곱창\", \"찜닭\", \"오리고기\", \"소고기\", \n",
    "          \"국밥\", \"닭도리탕\", \"낙곱새\", \"라면\", \"비빔밥\", \"칼국수\", \n",
    "          \"수제비\", \"갈비\", \"제육볶음\"]\n",
    "\n",
    "western = [\"스테이크\", \"파스타\", \"필라프\", \"감바스\", \"리조또\", \"샐러드\", \n",
    "           \"피자\", \"빠에야\", \"플래터\", \"스튜\"]\n",
    "\n",
    "asian = [\"짜장면\", \"뿌팟퐁커리\", \"팟타이\", \"나시고랭\", \"쌀국수\", \"미고랭\",\n",
    "         \"카레\", \"마라탕\", \"마라샹궈\", \"훠궈\", \"돈까스\", \"월남쌈\", \"라멘\", \n",
    "         \"탄탄멘\", \"규동\", \"꿔바로우\", \"똠양꿍\", \"물냉면\"]\n",
    "\n",
    "spicy = [\"떡볶이\", \"김치찜\", \"김치찌개\", \"감자탕\", \"짬뽕\", \"닭발\", \"부대찌개\",\n",
    "         \"순두부찌개\", \"아구찜\", \"해물찜\", \"육개장\", \"낙지볶음\", \"쭈꾸미\", \n",
    "         \"돼지갈비찜\", \"소꼬리찜\", \"비빔냉면\"]\n",
    "\n",
    "dessert = [\"와플\", \"마카롱\", \"빙수\", \"크로크모슈\", \"케이크\", \"허니바게트볼\",\n",
    "           \"머쉬룸수프볼\", \"에그데니쉬\", \"케이크\", \"치아바타\", \"호두파운드케이크\",\n",
    "           \"쿠키\", \"허니브레드\", \"오믈렛\", \"베이글\"]\n",
    "\n",
    "snack = [\"닭강정\", \"양꼬치\", \"핫윙\", \"소떡소떡\", \"가라아게\", \"콘치즈\", \"감자튀김\", \n",
    "         \"치킨너겟\", \"치킨\", \"낫쵸\", \"소시지\", \"버터구이\", \"계란찜\", \"핫도그\", \n",
    "         \"해쉬브라운\"]\n",
    "\n",
    "coffee = [\"아메리카노\", \"콜드브루\", \"바닐라 라떼\", \"카페 라떼\", \"카라멜 마키아또\",\n",
    "          \"카페 모카\", \"바닐라 프라페\", \"카페모카 프라페\", \"연유 라떼\", \"화이트 모카\",\n",
    "          \"민트 모카\", \"헤이즐넛 라떼\", \"에스프레소\", \"오곡 프라페\", \"쿠앤크 프라페\"]\n",
    "\n",
    "beverage = [\"초코 라떼\", \"민트초코 라떼\", \"밀크티\", \"흑당 버블티\", \"레몬차\", \"자몽차\",\n",
    "            \"유자차\", \"모히토\", \"요거트 스무디\", \"블루베리 스무디\", \"딸기 스무디\", \"애플망고 스무디\",\n",
    "            \"레몬 에이드\", \"자몽 에이드\", \"생과일 주스\"]\n",
    "\n",
    "motivation = [\"자신을 믿어라. 자신의 능력을 신뢰하라. 겸손하지만 합리적인 자신감 없이는 성공할 수도 행복할 수도 없다. - 노먼 빈센트 필\",\n",
    "\"조금 더 많이 인내하자. 조금 더 많이 노력하자. 그러면 절망적 실패로 보였던 것이 빛나는 성공으로 변할 수 있다. - 알버트 휴버드\",\n",
    "\"당신이 인생의 주인공이기 때문이다. 그 사실을 잊지말라. 지금까지 당신이 만들어온 의식적 그리고 무의식적 선택으로 인해 지금의 당신이 있는것이다. - 바바라 홀\",\n",
    "\"먹는 칼로리보다 에너지 소모가 적으면 살이 찌듯이, 걱정만 하고 행동하지 않으면 걱정이 찐다.\",\n",
    "\"이미 끝나버린 일을 후회하기 보다는 하고 싶었던 일을 하지 못한 것을 후회하라 - 탈무드\",\n",
    "\"기회가 주어지면 최선을 다하는 것이 아니라 최선을 다하고 있으면 기회가 주어지는 것이다 - 신영준\",\n",
    "\"낭비한 시간에 대한 후회는 더 큰 시간 낭비이다 - 메이슨 쿨리\",\n",
    "\"성공은 매일 부단하게 반복된 작은 노력의 합산이다.\",\n",
    "\"현명한 사람은 앉아서 손해 본 것을 한탄만 하지 않고 즐겁게 그 손해를 회복할 방법을 찾는다. - 셰익스피어\",\n",
    "\"고통을 주지 않는것은 쾌락도 주지 않는다 - 몽테뉴\",\n",
    "\"시간은 간다\",\n",
    "\"살아가는 사람들 중 대부분은 자신에게 올 기회를 기다리나 기회라는 것은 기다리는 사람에게는 쉽게 오지 않는 법이다\",\n",
    "\"기회를 얻을 수 있게 기다리는 사람이 되기보다는 기회를 얻을 수 있는 실력을 먼저 쌓아야 한다. 자신이 하는 일에 열중하고 노력하다보면 자연스럽게 기회는 찾아온다.\",\n",
    "\"변화를 위해서 가장 중요한 것은 행동하는 첫걸음이다.\",\n",
    "\"무엇이든 하루아침에 만들어지는 것은 없다. 로마 또한 하루아침에 만들어지지 않았다. 이 말은 무언가를 만들기 위해서는 그것을 만들기 위해 노력하고 집중 해야 한다는 것이다.\",\n",
    "\"스스로를 믿고 자신이 가지고 있는 능력을 신뢰해야 한다. 하지만 거만하게 행동하지 말고 겸손해라. 성공을 위해서 자신감이 필요하지만 오만함은 필요하지 않다.\",\n",
    "             \"끝난 일은 언급할 필요가 없으며 지난 일은 허물을 물을 필요가 없다. - 공자\",\n",
    "\"어렵고 힘든 상황일수록 서두르지 말고 침착해라. 성급하게 하는 행동에는 실수가 포함되기 쉽다.\",\n",
    "\"나의 하루를 설명할 수 있는 사람이 곁에 있다는 건 생각보다 기분 좋은 일이야 그러니 너도 생각보다 좋은 사람이지 - 흔글\",\n",
    "\"잠 못 자고 있지, 얼른 자, 걱정하는 일 안 생겨 좋은 일은 아니더라도 아무 일 없을 거야 혼자 있는 새벽을 걱정으로 보내지는 마 - 흔글\",\n",
    "\"봄바람도 살랑살랑 불고 꽃도 예쁘게 피어있으니 얼마나 놀고 싶겠냐만은, 그래도 그 시간들을 이겨내면 너의 인생에 꽃이 필 테니 조금만 참고 바람을 이겨내기를 - 흔글\"]\n",
    "\n",
    "category = [heal,extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f8 = [extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f6 = [extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,korean,western,asian,spicy,dessert,snack,coffee,beverage]\n",
    "f3 = [heal,extreme,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage, dessert]\n",
    "f1 = [heal,movie,k_balad,k_dance,k_hip,trt,f_dance,newage,korean,western,asian,spicy,dessert,snack,coffee,beverage, dessert]\n",
    "f0 = [heal,movie,k_balad,k_dance,k_hip,f_dance,newage,korean,western,asian,spicy,spicy,dessert,snack,snack,coffee,beverage]\n",
    "\n",
    "def recomend_sys(new_sentence):\n",
    "    global score\n",
    "    global timecheck\n",
    "    global corpus\n",
    "    global score\n",
    "    global avg_emo\n",
    "\n",
    "    print(new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new)) # 예측\n",
    "    \n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))\n",
    "      \n",
    "    corpus.append(score)\n",
    "    if len(corpus) >= 5:\n",
    "        avg_emo = sum(corpus)/len(corpus)\n",
    "        if(avg_emo > 0.8):\n",
    "            pick = random.choice(f8)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘처럼 좋은 날엔 {0} 어떠신가요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "\n",
    "        elif(avg_emo > 0.6): \n",
    "            pick = random.choice(f6)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"좋은 일있으신가요? 오늘 {0} 어떠세요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.4) :\n",
    "            pick = random.choice(category)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘같은 날에는 {0} 어때요? 기분이 좋아질거에요!!\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.3) :\n",
    "            pick = random.choice(f3)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"꿀꿀한 오늘 {0} 추천해요.\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        elif(avg_emo > 0.18) :\n",
    "            pick = random.choice(f1)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘 {0} 어떠세요? 안좋은 기분을 환기시켜줄 거에요.\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "        else:\n",
    "            pick = random.choice(f0)\n",
    "            if pick == motivation: # | pick == rest:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"당신을 위한 한마디 : {1}\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "            else:\n",
    "                print(\"기분 점수 : {0:.2f}\".format(avg_emo*100))\n",
    "                print(\"오늘 안좋은 일이 있으셨나요. 오늘같은 날 {0} 어떠세요?\\n\".format(random.choice(pick)))\n",
    "                corpus=[]\n",
    "    else:\n",
    "        print('감정 분석까지 {0}개의 문장이 남았어요!'.format(5-len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee550ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 한화팬입니다\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15180/2667844335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecomend_sys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'나는 한화팬입니다'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15180/2883446623.py\u001b[0m in \u001b[0;36mrecomend_sys\u001b[1;34m(new_sentence)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0mnew_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 토큰화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[0mnew_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_sentence\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_sentence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 정수 인코딩\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[0mpad_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 패딩\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "recomend_sys('나는 한화팬입니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd04df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
